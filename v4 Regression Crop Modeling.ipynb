{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q\n",
    "\n",
    "#####  Potential problems:\n",
    "*  SO Many slope values os close to 90: what does it mean?\n",
    "\n",
    "TODO:\n",
    "Try binning calories_per_ha: categorical prob ? dfTransformed = pd.cut(df[col], bins=5, labels=[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "#import hazelbean as hb\n",
    "#L = hb.get_logger()\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib \n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data preprocessing \n",
    "to be in Annex of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resampling pop data\n",
    "from osgeo import gdal, ogr, gdalconst, osr\n",
    "\n",
    "def reproject_raster(input_fn, match_fn, output_fn,\n",
    "                     interpolation_scheme=gdalconst.GRA_Bilinear,\n",
    "                     output_type=gdalconst.GDT_Float32,\n",
    "                    NoData =-99999):\n",
    "\n",
    "    # Source\n",
    "    src_filename = input_fn\n",
    "    src = gdal.Open(src_filename, gdalconst.GA_ReadOnly)\n",
    "    src_proj = src.GetProjection()\n",
    "    src_geotrans = src.GetGeoTransform()\n",
    "\n",
    "    # We want a section of source that matches this:\n",
    "    match_filename = match_fn\n",
    "    match_ds = gdal.Open(match_filename, gdalconst.GA_ReadOnly)\n",
    "    match_proj = match_ds.GetProjection()\n",
    "    match_geotrans = match_ds.GetGeoTransform()\n",
    "    wide = match_ds.RasterXSize\n",
    "    high = match_ds.RasterYSize\n",
    "\n",
    "    # Output / destination\n",
    "    dst_filename = output_fn\n",
    "    dst = gdal.GetDriverByName('GTiff').Create(dst_filename,\n",
    "                                               wide,                   # number of columns\n",
    "                                               high,                   # number of columns\n",
    "                                               1,                      # number of bands\n",
    "                                               output_type)  # datatype of the raster\n",
    "    dst.SetGeoTransform( match_geotrans )\n",
    "    dst.SetProjection(match_proj)\n",
    "    dst.GetRasterBand(1).SetNoDataValue(NoData)\n",
    "\n",
    "    # Do the work\n",
    "    gdal.ReprojectImage(src, dst, src_proj, match_proj, interpolation_scheme)\n",
    "\n",
    "    del dst # Flush\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reproject_raster('../ipbes_invest_crop_yield_project/input/Demographic/ciesin/gpw_v4_population_count_rev10_2000_30_sec.tif',\n",
    "                 '../ipbes_invest_crop_yield_project/input/Cartographic/country_ids.tif',\n",
    "                 '../ipbes_invest_crop_yield_project/input/Demographic/ciesin/gpw_population.tif',\n",
    "                 output_type=gdalconst.GDT_Int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reproject_raster('../ipbes_invest_crop_yield_project/input/Climate/Koeppen-Geiger/climate_zones_wrong_proj.tif',\n",
    "                 '../ipbes_invest_crop_yield_project/input/Cartographic/country_ids.tif',\n",
    "                 '../ipbes_invest_crop_yield_project/input/Climate/Koeppen-Geiger/climate_zones.tif',\n",
    "                 output_type=gdalconst.GDT_Int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Things to be added in load_data\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'bio12': 'precip', 'bio1': 'temperature',\n",
    "                       'minutes_to_market_5m':'min_to_market',\n",
    "                       'gdp_per_capita_2000_5m':'gdp_per_capita',\n",
    "                       'gdp_2000':'gdp'})\n",
    "\n",
    "df['log_precip'] = df['precip'].apply(lambda x: np.log(x) if x!=0 else 0)\n",
    "df['log_altitude'] = df['altitude'].apply(lambda x:np.log(x) if x!=0 else 0)\n",
    "df['log_gdp'] = df['gdp'].apply(lambda x:np.log(x) if x!=0 else 0)\n",
    "df['log_gdp_per_capita'] = df['gdp_per_capita'].apply(lambda x:np.log(x) if x!=0 else 0)\n",
    "df['log_min_to_market'] = df['min_to_market'].apply(lambda x:np.log(x) if x!=0 else 0)\n",
    "\n",
    "\n",
    "df['slope'] = df['slope'].replace({0:np.nan}) #143 NaN in 'slope' variable\n",
    "\n",
    "for soil_var in ['workability_index', 'toxicity_index','rooting_conditions_index', 'oxygen_availability_index',\n",
    "       'nutrient_retention_index', 'nutrient_availability_index','excess_salts_index']:\n",
    "    df[soil_var] = df[soil_var].replace({255:np.nan}) \n",
    "\n",
    "## TODO figure out how to encode soil variables\n",
    "\n",
    "df\n",
    "    \n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in df.columns:\n",
    "    fig,ax = plt.subplots()\n",
    "    df[var].plot(kind='kde',ax=ax);\n",
    "    ax.set_xlabel(var);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(subset=True):\n",
    "    #L.info('Loading data')\n",
    "    crop_types_df = pd.read_csv('../ipbes_invest_crop_yield_project/intermediate/aggregate_crops_by_type/aggregated_crop_data.csv')\n",
    "    df_land = pd.read_csv('../ipbes_invest_crop_yield_project/intermediate/create_baseline_regression_data/baseline_regression_data.csv')\n",
    "    #L.info('Data loaded')\n",
    "\n",
    "    df = crop_types_df.merge(df_land,how='outer',on='pixel_id')\n",
    "    #L.info('Data merged')\n",
    "\n",
    "    if subset==True:\n",
    "        df = df.sample(frac=0.02, replace=False, weights=None, random_state=None, axis=0)\n",
    "\n",
    "    elif subset==False: #Save validation data\n",
    "        x = df.drop(['calories_per_ha'], axis=1)\n",
    "        y = df['calories_per_ha']\n",
    "        X, X_validation, Y, y_validation = train_test_split(x, y)\n",
    "        df = X.merge(Y,how='outer',left_index=True,right_index=True)\n",
    "\n",
    "    #Remove cal_per_ha per crop type for now\n",
    "    df = df.drop(labels=['c3_annual_calories_per_ha', 'c3_perennial_calories_per_ha',\n",
    "           'c4_annual_calories_per_ha', 'c4_perennial_calories_per_ha',\n",
    "           'nitrogen_fixer_calories_per_ha'], axis=1)\n",
    "\n",
    "    #Remove helper columns (not features)\n",
    "    df = df.drop(labels=['Unnamed: 0', 'country_ids',\n",
    "           'ha_per_cell_5m'], axis=1)\n",
    "\n",
    "    # Rename cols\n",
    "    df = df.rename(columns={'bio12': 'precip', 'bio1': 'temperature',\n",
    "                                'minutes_to_market_5m': 'min_to_market',\n",
    "                                'gdp_per_capita_2000_5m': 'gdp_per_capita',\n",
    "                                'gdp_2000': 'gdp'})\n",
    "    # Encode properly NaNs\n",
    "    df['slope'] = df['slope'].replace({0: np.nan})  # 143 NaN in 'slope' variable\n",
    "    for soil_var in ['workability_index', 'toxicity_index', 'rooting_conditions_index', 'oxygen_availability_index',\n",
    "                     'nutrient_retention_index', 'nutrient_availability_index', 'excess_salts_index']:\n",
    "        df[soil_var] = df[soil_var].replace({255: np.nan})\n",
    "        \n",
    "    # Drop NaN\n",
    "    df = df.dropna()\n",
    "    df = df[df['calories_per_ha'] != 0]    \n",
    "    \n",
    "    #Encode climate zones (as str)\n",
    "    climate_zones_map = {1:'Af',2:'Am',3:'Aw',\n",
    "                     5:'BWk',4:'BWh',7:'BSk',6:'BSh',\n",
    "                     14:'Cfa',15:'Cfb',16:'Cfc',8:'Csa',\n",
    "                     9:'Csb',10:'Csc',11:'Cwa',12:'Cwb',13:'Cwc',\n",
    "                     25:'Dfa',26:'Dfb',27:'Dfc',28:'Dfd',17:'Dsa',18:'Dsb',19:'Dsc',\n",
    "                     20:'Dsd',21:'Dwa',22:'Dwb',23:'Dwc',24:'Dwd',\n",
    "                     30:'EF',29:'ET'}\n",
    "    df['climate_zones'] = df['climate_zones'].map(climate_zones_map)\n",
    "    \n",
    "    #Â Encode climate zones as dummies\n",
    "    climate_dummies_df = pd.get_dummies(df['climate_zones'])\n",
    "    for col in climate_dummies_df.columns:\n",
    "        climate_dummies_df = climate_dummies_df.rename({col:str('climatezone_'+col)},axis=1)\n",
    "    \n",
    "    df = df.merge(climate_dummies_df, right_index=True,left_index=True)\n",
    "    df = df.drop('climate_zones',axis=1)\n",
    "    \n",
    "    # Log some skewed variables\n",
    "    df['calories_per_ha'] = df['calories_per_ha'].apply(lambda x: np.log(x) if x != 0 else 0)\n",
    "\n",
    "    for col in ['gdp_per_capita','altitude', 'min_to_market', 'gpw_population']:\n",
    "        df[str('log_'+col)] = df[col].apply(lambda x: np.log(x) if x != 0 else 0)\n",
    "\n",
    "\n",
    "    # Encode properly NaNs\n",
    "    df['slope'] = df['slope'].replace({0: np.nan})  # 143 NaN in 'slope' variable\n",
    "    for soil_var in ['workability_index', 'toxicity_index', 'rooting_conditions_index', 'oxygen_availability_index',\n",
    "                     'nutrient_retention_index', 'nutrient_availability_index', 'excess_salts_index']:\n",
    "        df[soil_var] = df[soil_var].replace({255: np.nan})\n",
    "            \n",
    "    df = df.set_index('pixel_id')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in df.columns:\n",
    "    fig,ax = plt.subplots()\n",
    "    df[var].plot(kind='kde',ax=ax);\n",
    "    ax.set_xlabel(var);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(20,5));\n",
    "sns.distplot(df[df['calories_per_ha']!=0]['calories_per_ha'],ax=ax);\n",
    "\n",
    "#Lines at mean, 75%, 90%, and 99%\n",
    "plt.axvline(df['calories_per_ha'].mean(), color='k', linestyle='dashed', linewidth=1);\n",
    "plt.axvline(df['calories_per_ha'].quantile(0.75), color='b', linestyle='dashed', linewidth=1);\n",
    "plt.axvline(df['calories_per_ha'].quantile(0.9), color='r', linestyle='dashed', linewidth=1);\n",
    "plt.axvline(df['calories_per_ha'].quantile(0.99), color='g', linestyle='dashed', linewidth=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_polynomial(df, degree = 2, interaction_terms = True):\n",
    "#'''Returns a new dataFrame with added polynomial terms degree >= 2'''\n",
    "\n",
    "\n",
    "    if interaction_terms == False:\n",
    "        x = df.drop(['calories_per_ha','climate_zones'], axis=1)\n",
    "        y = df['calories_per_ha']\n",
    "\n",
    "        for deg in range(2,degree+1):\n",
    "            for col in x.columns:\n",
    "                x[str(col+'^'+str(deg))] = x[col].apply(lambda x:x**deg)\n",
    "        \n",
    "        Poly_df = x.merge(pd.DataFrame(y),right_index=True,left_index=True)\n",
    "\n",
    "    if interaction_terms == True:\n",
    "        x = df.drop(['calories_per_ha','climate_zones'], axis=1)\n",
    "        y = df['calories_per_ha'].reset_index()\n",
    "\n",
    "        poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "        X2 = poly.fit_transform(x)\n",
    "\n",
    "        Poly_df = pd.DataFrame(data = np.concatenate((y.as_matrix(),X2),axis=1),\n",
    "                               columns = ['pixel_id','calories_per_ha'] +\n",
    "                               poly.get_feature_names((df.drop(['calories_per_ha','climate_zones'], axis=1)).columns))\n",
    "\n",
    "        Poly_df = Poly_df.set_index('pixel_id')\n",
    "\n",
    "    return Poly_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results= pd.DataFrame(columns=['Model','num_features','Features','MSE','R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>num_features</th>\n",
       "      <th>Features</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>5</td>\n",
       "      <td>[toxicity_index, rooting_conditions_index, nut...</td>\n",
       "      <td>-0.008604</td>\n",
       "      <td>0.121383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>6</td>\n",
       "      <td>[toxicity_index, rooting_conditions_index, nut...</td>\n",
       "      <td>-0.008512</td>\n",
       "      <td>0.131148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>7</td>\n",
       "      <td>[toxicity_index, rooting_conditions_index, nut...</td>\n",
       "      <td>-0.008494</td>\n",
       "      <td>0.132957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>8</td>\n",
       "      <td>[toxicity_index, rooting_conditions_index, nut...</td>\n",
       "      <td>-0.008493</td>\n",
       "      <td>0.133093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>9</td>\n",
       "      <td>[toxicity_index, rooting_conditions_index, nut...</td>\n",
       "      <td>-0.008494</td>\n",
       "      <td>0.132958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>10</td>\n",
       "      <td>[toxicity_index, rooting_conditions_index, nut...</td>\n",
       "      <td>-0.008215</td>\n",
       "      <td>0.161261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>11</td>\n",
       "      <td>[toxicity_index, rooting_conditions_index, nut...</td>\n",
       "      <td>-0.008182</td>\n",
       "      <td>0.164579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>12</td>\n",
       "      <td>[toxicity_index, rooting_conditions_index, nut...</td>\n",
       "      <td>-0.008184</td>\n",
       "      <td>0.164461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>13</td>\n",
       "      <td>[toxicity_index, rooting_conditions_index, nut...</td>\n",
       "      <td>-0.008175</td>\n",
       "      <td>0.165415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>14</td>\n",
       "      <td>[toxicity_index, rooting_conditions_index, pro...</td>\n",
       "      <td>-0.008175</td>\n",
       "      <td>0.165405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>15</td>\n",
       "      <td>[workability_index, toxicity_index, rooting_co...</td>\n",
       "      <td>-0.008143</td>\n",
       "      <td>0.168819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>16</td>\n",
       "      <td>[workability_index, toxicity_index, rooting_co...</td>\n",
       "      <td>-0.007957</td>\n",
       "      <td>0.188289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>17</td>\n",
       "      <td>[slope, toxicity_index, rooting_conditions_ind...</td>\n",
       "      <td>-0.007957</td>\n",
       "      <td>0.188378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>18</td>\n",
       "      <td>[workability_index, toxicity_index, rooting_co...</td>\n",
       "      <td>-0.007958</td>\n",
       "      <td>0.188228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>19</td>\n",
       "      <td>[slope, workability_index, toxicity_index, roo...</td>\n",
       "      <td>-0.007959</td>\n",
       "      <td>0.188201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[slope, temp_avg, temp_isothermality, precip, ...</td>\n",
       "      <td>-0.007140</td>\n",
       "      <td>0.272384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XGB</td>\n",
       "      <td>6</td>\n",
       "      <td>[slope, temp_isothermality, temp_seasonality, ...</td>\n",
       "      <td>-0.007153</td>\n",
       "      <td>0.271551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGB</td>\n",
       "      <td>7</td>\n",
       "      <td>[slope, gdp_2000, temp_avg, temp_isothermality...</td>\n",
       "      <td>-0.006988</td>\n",
       "      <td>0.288531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>XGB</td>\n",
       "      <td>8</td>\n",
       "      <td>[slope, gdp_2000, gdp_per_capita_2000_5m, temp...</td>\n",
       "      <td>-0.006850</td>\n",
       "      <td>0.303025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGB</td>\n",
       "      <td>9</td>\n",
       "      <td>[slope, gdp_2000, gdp_per_capita_2000_5m, temp...</td>\n",
       "      <td>-0.006735</td>\n",
       "      <td>0.314144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XGB</td>\n",
       "      <td>10</td>\n",
       "      <td>[slope, altitude, gdp_2000, gpw_population, te...</td>\n",
       "      <td>-0.006765</td>\n",
       "      <td>0.312061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGB</td>\n",
       "      <td>11</td>\n",
       "      <td>[slope, altitude, gdp_2000, gdp_per_capita_200...</td>\n",
       "      <td>-0.006610</td>\n",
       "      <td>0.327771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>XGB</td>\n",
       "      <td>12</td>\n",
       "      <td>[slope, altitude, gdp_2000, gdp_per_capita_200...</td>\n",
       "      <td>-0.006644</td>\n",
       "      <td>0.323681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XGB</td>\n",
       "      <td>13</td>\n",
       "      <td>[slope, altitude, gdp_2000, gdp_per_capita_200...</td>\n",
       "      <td>-0.006611</td>\n",
       "      <td>0.327568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>XGB</td>\n",
       "      <td>14</td>\n",
       "      <td>[slope, altitude, gdp_2000, gdp_per_capita_200...</td>\n",
       "      <td>-0.006600</td>\n",
       "      <td>0.328831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>XGB</td>\n",
       "      <td>15</td>\n",
       "      <td>[slope, altitude, gdp_2000, gdp_per_capita_200...</td>\n",
       "      <td>-0.006632</td>\n",
       "      <td>0.324964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>XGB</td>\n",
       "      <td>16</td>\n",
       "      <td>[slope, altitude, gdp_2000, gdp_per_capita_200...</td>\n",
       "      <td>-0.006637</td>\n",
       "      <td>0.324769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>XGB</td>\n",
       "      <td>17</td>\n",
       "      <td>[slope, altitude, gdp_2000, gdp_per_capita_200...</td>\n",
       "      <td>-0.006656</td>\n",
       "      <td>0.322632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XGB</td>\n",
       "      <td>18</td>\n",
       "      <td>[slope, altitude, rooting_conditions_index, gd...</td>\n",
       "      <td>-0.006639</td>\n",
       "      <td>0.324464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XGB</td>\n",
       "      <td>19</td>\n",
       "      <td>[slope, altitude, nutrient_retention_index, gd...</td>\n",
       "      <td>-0.006686</td>\n",
       "      <td>0.319525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>XGB</td>\n",
       "      <td>20</td>\n",
       "      <td>[slope, altitude, nutrient_retention_index, gd...</td>\n",
       "      <td>-0.006677</td>\n",
       "      <td>0.320983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>XGB</td>\n",
       "      <td>21</td>\n",
       "      <td>[slope, altitude, rooting_conditions_index, nu...</td>\n",
       "      <td>-0.006617</td>\n",
       "      <td>0.326192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>XGB</td>\n",
       "      <td>22</td>\n",
       "      <td>[slope, altitude, rooting_conditions_index, nu...</td>\n",
       "      <td>-0.006621</td>\n",
       "      <td>0.325979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>XGB</td>\n",
       "      <td>23</td>\n",
       "      <td>[slope, altitude, rooting_conditions_index, ox...</td>\n",
       "      <td>-0.006621</td>\n",
       "      <td>0.325979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>XGB</td>\n",
       "      <td>24</td>\n",
       "      <td>[slope, altitude, workability_index, rooting_c...</td>\n",
       "      <td>-0.006625</td>\n",
       "      <td>0.325545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>XGB</td>\n",
       "      <td>25</td>\n",
       "      <td>[slope, altitude, rooting_conditions_index, pr...</td>\n",
       "      <td>-0.006621</td>\n",
       "      <td>0.326058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>XGB</td>\n",
       "      <td>26</td>\n",
       "      <td>[slope, altitude, rooting_conditions_index, pr...</td>\n",
       "      <td>-0.006617</td>\n",
       "      <td>0.326337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>XGB</td>\n",
       "      <td>27</td>\n",
       "      <td>[slope, altitude, workability_index, rooting_c...</td>\n",
       "      <td>-0.006621</td>\n",
       "      <td>0.325858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>XGB</td>\n",
       "      <td>28</td>\n",
       "      <td>[slope, altitude, workability_index, toxicity_...</td>\n",
       "      <td>-0.006620</td>\n",
       "      <td>0.325847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Poly deg2</td>\n",
       "      <td>5</td>\n",
       "      <td>[rooting_conditions_index, oxygen_availability...</td>\n",
       "      <td>-0.009604</td>\n",
       "      <td>0.018225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Poly deg2</td>\n",
       "      <td>6</td>\n",
       "      <td>[toxicity_index, rooting_conditions_index, tem...</td>\n",
       "      <td>-0.009613</td>\n",
       "      <td>0.017476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Poly deg2</td>\n",
       "      <td>7</td>\n",
       "      <td>[nutrient_availability_index, excess_salts_ind...</td>\n",
       "      <td>-0.009271</td>\n",
       "      <td>0.053359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Poly deg2</td>\n",
       "      <td>8</td>\n",
       "      <td>[minutes_to_market_5m, precip_wet_mth, minutes...</td>\n",
       "      <td>-0.008766</td>\n",
       "      <td>0.104580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Poly deg2</td>\n",
       "      <td>9</td>\n",
       "      <td>[toxicity_index, protected_areas_index, nutrie...</td>\n",
       "      <td>-0.009219</td>\n",
       "      <td>0.058073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Poly deg3</td>\n",
       "      <td>5</td>\n",
       "      <td>[protected_areas_index, nutrient_retention_ind...</td>\n",
       "      <td>-0.009631</td>\n",
       "      <td>0.015671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Poly deg3</td>\n",
       "      <td>6</td>\n",
       "      <td>[protected_areas_index, temp_annualmax, temp_a...</td>\n",
       "      <td>-0.009608</td>\n",
       "      <td>0.017776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Poly deg3</td>\n",
       "      <td>7</td>\n",
       "      <td>[workability_index, nutrient_retention_index, ...</td>\n",
       "      <td>-0.009004</td>\n",
       "      <td>0.080447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Poly deg3</td>\n",
       "      <td>8</td>\n",
       "      <td>[workability_index, toxicity_index, rooting_co...</td>\n",
       "      <td>-0.009300</td>\n",
       "      <td>0.049774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Poly deg3</td>\n",
       "      <td>9</td>\n",
       "      <td>[oxygen_availability_index, nutrient_retention...</td>\n",
       "      <td>-0.009069</td>\n",
       "      <td>0.073137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Poly deg2 w/ interact</td>\n",
       "      <td>5</td>\n",
       "      <td>[nutrient_availability_index, temp_annualmin, ...</td>\n",
       "      <td>-0.009494</td>\n",
       "      <td>0.029081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Poly deg2 w/ interact</td>\n",
       "      <td>6</td>\n",
       "      <td>[workability_index, nutrient_retention_index, ...</td>\n",
       "      <td>-0.009483</td>\n",
       "      <td>0.030499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Poly deg2 w/ interact</td>\n",
       "      <td>7</td>\n",
       "      <td>[toxicity_index, protected_areas_index, nutrie...</td>\n",
       "      <td>-0.009694</td>\n",
       "      <td>0.009087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Poly deg2 w/ interact</td>\n",
       "      <td>8</td>\n",
       "      <td>[workability_index, nutrient_retention_index, ...</td>\n",
       "      <td>-0.009578</td>\n",
       "      <td>0.021014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Poly deg2 w/ interact</td>\n",
       "      <td>9</td>\n",
       "      <td>[altitude, minutes_to_market_5m, precip, altit...</td>\n",
       "      <td>-0.008435</td>\n",
       "      <td>0.138411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Poly deg3 w/ interact</td>\n",
       "      <td>5</td>\n",
       "      <td>[workability_index, nutrient_retention_index, ...</td>\n",
       "      <td>-0.009374</td>\n",
       "      <td>0.041473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Poly deg3 w/ interact</td>\n",
       "      <td>6</td>\n",
       "      <td>[workability_index, nutrient_retention_index, ...</td>\n",
       "      <td>-0.009114</td>\n",
       "      <td>0.069369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Poly deg3 w/ interact</td>\n",
       "      <td>7</td>\n",
       "      <td>[workability_index, oxygen_availability_index,...</td>\n",
       "      <td>-0.009062</td>\n",
       "      <td>0.074636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Poly deg3 w/ interact</td>\n",
       "      <td>8</td>\n",
       "      <td>[workability_index, rooting_conditions_index, ...</td>\n",
       "      <td>-0.009441</td>\n",
       "      <td>0.034882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Poly deg3 w/ interact</td>\n",
       "      <td>9</td>\n",
       "      <td>[workability_index, toxicity_index, protected_...</td>\n",
       "      <td>-0.009570</td>\n",
       "      <td>0.021969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model num_features  \\\n",
       "0       Linear Regression            5   \n",
       "1       Linear Regression            6   \n",
       "2       Linear Regression            7   \n",
       "3       Linear Regression            8   \n",
       "4       Linear Regression            9   \n",
       "5       Linear Regression           10   \n",
       "6       Linear Regression           11   \n",
       "7       Linear Regression           12   \n",
       "8       Linear Regression           13   \n",
       "9       Linear Regression           14   \n",
       "10      Linear Regression           15   \n",
       "11      Linear Regression           16   \n",
       "12      Linear Regression           17   \n",
       "13      Linear Regression           18   \n",
       "14      Linear Regression           19   \n",
       "15                    XGB            5   \n",
       "16                    XGB            6   \n",
       "17                    XGB            7   \n",
       "18                    XGB            8   \n",
       "19                    XGB            9   \n",
       "20                    XGB           10   \n",
       "21                    XGB           11   \n",
       "22                    XGB           12   \n",
       "23                    XGB           13   \n",
       "24                    XGB           14   \n",
       "25                    XGB           15   \n",
       "26                    XGB           16   \n",
       "27                    XGB           17   \n",
       "28                    XGB           18   \n",
       "29                    XGB           19   \n",
       "30                    XGB           20   \n",
       "31                    XGB           21   \n",
       "32                    XGB           22   \n",
       "33                    XGB           23   \n",
       "34                    XGB           24   \n",
       "35                    XGB           25   \n",
       "36                    XGB           26   \n",
       "37                    XGB           27   \n",
       "38                    XGB           28   \n",
       "39              Poly deg2            5   \n",
       "40              Poly deg2            6   \n",
       "41              Poly deg2            7   \n",
       "42              Poly deg2            8   \n",
       "43              Poly deg2            9   \n",
       "44              Poly deg3            5   \n",
       "45              Poly deg3            6   \n",
       "46              Poly deg3            7   \n",
       "47              Poly deg3            8   \n",
       "48              Poly deg3            9   \n",
       "49  Poly deg2 w/ interact            5   \n",
       "50  Poly deg2 w/ interact            6   \n",
       "51  Poly deg2 w/ interact            7   \n",
       "52  Poly deg2 w/ interact            8   \n",
       "53  Poly deg2 w/ interact            9   \n",
       "54  Poly deg3 w/ interact            5   \n",
       "55  Poly deg3 w/ interact            6   \n",
       "56  Poly deg3 w/ interact            7   \n",
       "57  Poly deg3 w/ interact            8   \n",
       "58  Poly deg3 w/ interact            9   \n",
       "\n",
       "                                             Features       MSE        R2  \n",
       "0   [toxicity_index, rooting_conditions_index, nut... -0.008604  0.121383  \n",
       "1   [toxicity_index, rooting_conditions_index, nut... -0.008512  0.131148  \n",
       "2   [toxicity_index, rooting_conditions_index, nut... -0.008494  0.132957  \n",
       "3   [toxicity_index, rooting_conditions_index, nut... -0.008493  0.133093  \n",
       "4   [toxicity_index, rooting_conditions_index, nut... -0.008494  0.132958  \n",
       "5   [toxicity_index, rooting_conditions_index, nut... -0.008215  0.161261  \n",
       "6   [toxicity_index, rooting_conditions_index, nut... -0.008182  0.164579  \n",
       "7   [toxicity_index, rooting_conditions_index, nut... -0.008184  0.164461  \n",
       "8   [toxicity_index, rooting_conditions_index, nut... -0.008175  0.165415  \n",
       "9   [toxicity_index, rooting_conditions_index, pro... -0.008175  0.165405  \n",
       "10  [workability_index, toxicity_index, rooting_co... -0.008143  0.168819  \n",
       "11  [workability_index, toxicity_index, rooting_co... -0.007957  0.188289  \n",
       "12  [slope, toxicity_index, rooting_conditions_ind... -0.007957  0.188378  \n",
       "13  [workability_index, toxicity_index, rooting_co... -0.007958  0.188228  \n",
       "14  [slope, workability_index, toxicity_index, roo... -0.007959  0.188201  \n",
       "15  [slope, temp_avg, temp_isothermality, precip, ... -0.007140  0.272384  \n",
       "16  [slope, temp_isothermality, temp_seasonality, ... -0.007153  0.271551  \n",
       "17  [slope, gdp_2000, temp_avg, temp_isothermality... -0.006988  0.288531  \n",
       "18  [slope, gdp_2000, gdp_per_capita_2000_5m, temp... -0.006850  0.303025  \n",
       "19  [slope, gdp_2000, gdp_per_capita_2000_5m, temp... -0.006735  0.314144  \n",
       "20  [slope, altitude, gdp_2000, gpw_population, te... -0.006765  0.312061  \n",
       "21  [slope, altitude, gdp_2000, gdp_per_capita_200... -0.006610  0.327771  \n",
       "22  [slope, altitude, gdp_2000, gdp_per_capita_200... -0.006644  0.323681  \n",
       "23  [slope, altitude, gdp_2000, gdp_per_capita_200... -0.006611  0.327568  \n",
       "24  [slope, altitude, gdp_2000, gdp_per_capita_200... -0.006600  0.328831  \n",
       "25  [slope, altitude, gdp_2000, gdp_per_capita_200... -0.006632  0.324964  \n",
       "26  [slope, altitude, gdp_2000, gdp_per_capita_200... -0.006637  0.324769  \n",
       "27  [slope, altitude, gdp_2000, gdp_per_capita_200... -0.006656  0.322632  \n",
       "28  [slope, altitude, rooting_conditions_index, gd... -0.006639  0.324464  \n",
       "29  [slope, altitude, nutrient_retention_index, gd... -0.006686  0.319525  \n",
       "30  [slope, altitude, nutrient_retention_index, gd... -0.006677  0.320983  \n",
       "31  [slope, altitude, rooting_conditions_index, nu... -0.006617  0.326192  \n",
       "32  [slope, altitude, rooting_conditions_index, nu... -0.006621  0.325979  \n",
       "33  [slope, altitude, rooting_conditions_index, ox... -0.006621  0.325979  \n",
       "34  [slope, altitude, workability_index, rooting_c... -0.006625  0.325545  \n",
       "35  [slope, altitude, rooting_conditions_index, pr... -0.006621  0.326058  \n",
       "36  [slope, altitude, rooting_conditions_index, pr... -0.006617  0.326337  \n",
       "37  [slope, altitude, workability_index, rooting_c... -0.006621  0.325858  \n",
       "38  [slope, altitude, workability_index, toxicity_... -0.006620  0.325847  \n",
       "39  [rooting_conditions_index, oxygen_availability... -0.009604  0.018225  \n",
       "40  [toxicity_index, rooting_conditions_index, tem... -0.009613  0.017476  \n",
       "41  [nutrient_availability_index, excess_salts_ind... -0.009271  0.053359  \n",
       "42  [minutes_to_market_5m, precip_wet_mth, minutes... -0.008766  0.104580  \n",
       "43  [toxicity_index, protected_areas_index, nutrie... -0.009219  0.058073  \n",
       "44  [protected_areas_index, nutrient_retention_ind... -0.009631  0.015671  \n",
       "45  [protected_areas_index, temp_annualmax, temp_a... -0.009608  0.017776  \n",
       "46  [workability_index, nutrient_retention_index, ... -0.009004  0.080447  \n",
       "47  [workability_index, toxicity_index, rooting_co... -0.009300  0.049774  \n",
       "48  [oxygen_availability_index, nutrient_retention... -0.009069  0.073137  \n",
       "49  [nutrient_availability_index, temp_annualmin, ... -0.009494  0.029081  \n",
       "50  [workability_index, nutrient_retention_index, ... -0.009483  0.030499  \n",
       "51  [toxicity_index, protected_areas_index, nutrie... -0.009694  0.009087  \n",
       "52  [workability_index, nutrient_retention_index, ... -0.009578  0.021014  \n",
       "53  [altitude, minutes_to_market_5m, precip, altit... -0.008435  0.138411  \n",
       "54  [workability_index, nutrient_retention_index, ... -0.009374  0.041473  \n",
       "55  [workability_index, nutrient_retention_index, ... -0.009114  0.069369  \n",
       "56  [workability_index, oxygen_availability_index,... -0.009062  0.074636  \n",
       "57  [workability_index, rooting_conditions_index, ... -0.009441  0.034882  \n",
       "58  [workability_index, toxicity_index, protected_... -0.009570  0.021969  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "### - - - - - - - - - - - - - - - -  Linear regression - - - - - - - - - - - - - - - - \n",
    "### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "\n",
    "regression = LinearRegression()\n",
    "\n",
    "model = 'Linear Reg'\n",
    "\n",
    "dataframe = df\n",
    "        \n",
    "\n",
    "# Iterate over â  numbers of features\n",
    "for num_features in range (5,10):\n",
    "\n",
    "    ## RFE - Features selection\n",
    "    selector = RFE(regression, num_features, step=1)\n",
    "\n",
    "    x = dataframe.drop(['calories_per_ha','climate_zones'], axis=1) ## TODO climate_zones encode One Hot Encoder\n",
    "    y = dataframe['calories_per_ha']\n",
    "    X, X_test, Y, Y_test = train_test_split(x, y)\n",
    "\n",
    "    X_RFE = selector.fit_transform(X,Y)\n",
    "\n",
    "    features_selected = [X.columns[feature_pos] for feature_pos in selector.get_support(indices=True)]\n",
    "    features_selected.append('calories_per_ha')\n",
    "    scores = do_regression(regression,dataframe[features_selected])\n",
    "    R2_score = scores[0]\n",
    "    MSE_score = scores[1]\n",
    "    MAE_score = scores[2]\n",
    "\n",
    "    results = results.append({'Model': model,\n",
    "                              'num_features':num_features,\n",
    "                              'Features':features_selected,\n",
    "                              'R2':R2_score,\n",
    "                              'MSE':MSE_score},\n",
    "                             ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Polynomial of degree 2\n",
      "Doing regression with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done\n",
      "Doing regression with 6 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done\n",
      "Doing regression with 7 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done\n",
      "Doing regression with 8 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done\n",
      "Doing regression with 9 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done\n",
      "Running Polynomial of degree 3\n",
      "Doing regression with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done\n",
      "Doing regression with 6 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done\n",
      "Doing regression with 7 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done\n",
      "Doing regression with 8 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done\n",
      "Doing regression with 9 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done\n",
      "Running Polynomial of degree 2 with interaction terms\n",
      "Doing regression with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done\n",
      "Doing regression with 6 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done\n",
      "Doing regression with 7 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done\n",
      "Doing regression with 8 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done\n",
      "Doing regression with 9 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done\n",
      "Running Polynomial of degree 3 with interaction terms\n",
      "Doing regression with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done\n",
      "Doing regression with 6 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done\n",
      "Doing regression with 7 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done\n",
      "Doing regression with 8 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done\n",
      "Doing regression with 9 features ...\n",
      "... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "### - - - - - - - - - - - - - - - -  Polynomial regression - - - - - - - - - - - - - - - - \n",
    "### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "\n",
    "\n",
    "regression = LinearRegression()\n",
    "\n",
    "for interaction_terms in [False,True]:\n",
    "    for degree in [2,3]:\n",
    "        \n",
    "        print('Running Polynomial of degree ' + str(degree)+ interaction_terms*(' with interaction terms'))\n",
    "        \n",
    "        \n",
    "        model = str('Poly deg'+str(degree)+interaction_terms*' w/ interact')\n",
    "\n",
    "        dataframe = make_polynomial(df)\n",
    "\n",
    "        \n",
    "\n",
    "        # Iterate over â  numbers of features\n",
    "        for num_features in range (5,10):\n",
    "            \n",
    "            print('  Doing regression with '+str(num_features)+ ' features ...')\n",
    "\n",
    "            ## RFE - Features selection\n",
    "            selector = RFE(regression, num_features, step=1)\n",
    "\n",
    "            x = dataframe.drop(['calories_per_ha'], axis=1) ## TODO climate_zones encode One Hot Encoder\n",
    "            y = dataframe['calories_per_ha']\n",
    "            X, X_test, Y, Y_test = train_test_split(x, y)\n",
    "\n",
    "            X_RFE = selector.fit_transform(X,Y)\n",
    "\n",
    "            features_selected = [X.columns[feature_pos] for feature_pos in selector.get_support(indices=True)]\n",
    "            features_selected.append('calories_per_ha')\n",
    "            scores = do_regression(regression,dataframe[features_selected])\n",
    "            R2_score = scores[0]\n",
    "            MSE_score = scores[1]\n",
    "            MAE_score = scores[2]\n",
    "\n",
    "            results = results.append({'Model': model,\n",
    "                                      'num_features':num_features,\n",
    "                                      'Features':features_selected,\n",
    "                                      'R2':R2_score,\n",
    "                                      'MSE':MSE_score},\n",
    "                                     ignore_index=True)\n",
    "            \n",
    "            print('  ... done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "### - - - - - - - - - - - - - - - - -  XGB - - - - - - - - - - - - - - - - - - - - - - - \n",
    "### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "model = 'XGB'\n",
    "\n",
    "\n",
    "regression = xgb.XGBRegressor()\n",
    "\n",
    "print('Running XGBoost')\n",
    "\n",
    "# Iterate over â  numbers of features\n",
    "for num_features in range (5,6):\n",
    "    \n",
    "    print('    with '+str(num_features)+ ' features ...')\n",
    "    \n",
    "    ## RFE - Features selection\n",
    "    selector = RFE(regression, num_features, step=1)\n",
    "\n",
    "    x = df.drop(['calories_per_ha','climate_zones'], axis=1) ## TODO climate_zones encode One Hot Encoder\n",
    "    y = df['calories_per_ha']\n",
    "    X, X_test, Y, Y_test = train_test_split(x, y)\n",
    "\n",
    "    X_RFE = selector.fit_transform(X,Y)\n",
    "\n",
    "    features_selected = [X.columns[feature_pos] for feature_pos in selector.get_support(indices=True)]\n",
    "    features_selected.append('calories_per_ha')\n",
    "    scores = do_regression(regression,df[features_selected])\n",
    "    R2_score = scores[0]\n",
    "    MSE_score = scores[1]\n",
    "    MAE_score = scores[2]\n",
    "    \n",
    "    results = results.append({'Model': model,\n",
    "                              'num_features':num_features,\n",
    "                              'Features':features_selected,\n",
    "                              'R2':R2_score,\n",
    "                              'MSE':MSE_score},\n",
    "                             ignore_index=True)\n",
    "    \n",
    "    \n",
    "    print('    ... done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>num_features</th>\n",
       "      <th>Features</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>5</td>\n",
       "      <td>[toxicity_index, rooting_conditions_index, nut...</td>\n",
       "      <td>-0.008604</td>\n",
       "      <td>0.121383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>6</td>\n",
       "      <td>[toxicity_index, rooting_conditions_index, nut...</td>\n",
       "      <td>-0.008512</td>\n",
       "      <td>0.131148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>7</td>\n",
       "      <td>[toxicity_index, rooting_conditions_index, nut...</td>\n",
       "      <td>-0.008494</td>\n",
       "      <td>0.132957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>8</td>\n",
       "      <td>[toxicity_index, rooting_conditions_index, nut...</td>\n",
       "      <td>-0.008493</td>\n",
       "      <td>0.133093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>9</td>\n",
       "      <td>[toxicity_index, rooting_conditions_index, nut...</td>\n",
       "      <td>-0.008494</td>\n",
       "      <td>0.132958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>10</td>\n",
       "      <td>[toxicity_index, rooting_conditions_index, nut...</td>\n",
       "      <td>-0.008215</td>\n",
       "      <td>0.161261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>11</td>\n",
       "      <td>[toxicity_index, rooting_conditions_index, nut...</td>\n",
       "      <td>-0.008182</td>\n",
       "      <td>0.164579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>12</td>\n",
       "      <td>[toxicity_index, rooting_conditions_index, nut...</td>\n",
       "      <td>-0.008184</td>\n",
       "      <td>0.164461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>13</td>\n",
       "      <td>[toxicity_index, rooting_conditions_index, nut...</td>\n",
       "      <td>-0.008175</td>\n",
       "      <td>0.165415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>14</td>\n",
       "      <td>[toxicity_index, rooting_conditions_index, pro...</td>\n",
       "      <td>-0.008175</td>\n",
       "      <td>0.165405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>15</td>\n",
       "      <td>[workability_index, toxicity_index, rooting_co...</td>\n",
       "      <td>-0.008143</td>\n",
       "      <td>0.168819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>16</td>\n",
       "      <td>[workability_index, toxicity_index, rooting_co...</td>\n",
       "      <td>-0.007957</td>\n",
       "      <td>0.188289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>17</td>\n",
       "      <td>[slope, toxicity_index, rooting_conditions_ind...</td>\n",
       "      <td>-0.007957</td>\n",
       "      <td>0.188378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>18</td>\n",
       "      <td>[workability_index, toxicity_index, rooting_co...</td>\n",
       "      <td>-0.007958</td>\n",
       "      <td>0.188228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>19</td>\n",
       "      <td>[slope, workability_index, toxicity_index, roo...</td>\n",
       "      <td>-0.007959</td>\n",
       "      <td>0.188201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[slope, temp_avg, temp_isothermality, precip, ...</td>\n",
       "      <td>-0.007140</td>\n",
       "      <td>0.272384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XGB</td>\n",
       "      <td>6</td>\n",
       "      <td>[slope, temp_isothermality, temp_seasonality, ...</td>\n",
       "      <td>-0.007153</td>\n",
       "      <td>0.271551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGB</td>\n",
       "      <td>7</td>\n",
       "      <td>[slope, gdp_2000, temp_avg, temp_isothermality...</td>\n",
       "      <td>-0.006988</td>\n",
       "      <td>0.288531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>XGB</td>\n",
       "      <td>8</td>\n",
       "      <td>[slope, gdp_2000, gdp_per_capita_2000_5m, temp...</td>\n",
       "      <td>-0.006850</td>\n",
       "      <td>0.303025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGB</td>\n",
       "      <td>9</td>\n",
       "      <td>[slope, gdp_2000, gdp_per_capita_2000_5m, temp...</td>\n",
       "      <td>-0.006735</td>\n",
       "      <td>0.314144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XGB</td>\n",
       "      <td>10</td>\n",
       "      <td>[slope, altitude, gdp_2000, gpw_population, te...</td>\n",
       "      <td>-0.006765</td>\n",
       "      <td>0.312061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGB</td>\n",
       "      <td>11</td>\n",
       "      <td>[slope, altitude, gdp_2000, gdp_per_capita_200...</td>\n",
       "      <td>-0.006610</td>\n",
       "      <td>0.327771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>XGB</td>\n",
       "      <td>12</td>\n",
       "      <td>[slope, altitude, gdp_2000, gdp_per_capita_200...</td>\n",
       "      <td>-0.006644</td>\n",
       "      <td>0.323681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XGB</td>\n",
       "      <td>13</td>\n",
       "      <td>[slope, altitude, gdp_2000, gdp_per_capita_200...</td>\n",
       "      <td>-0.006611</td>\n",
       "      <td>0.327568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>XGB</td>\n",
       "      <td>14</td>\n",
       "      <td>[slope, altitude, gdp_2000, gdp_per_capita_200...</td>\n",
       "      <td>-0.006600</td>\n",
       "      <td>0.328831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>XGB</td>\n",
       "      <td>15</td>\n",
       "      <td>[slope, altitude, gdp_2000, gdp_per_capita_200...</td>\n",
       "      <td>-0.006632</td>\n",
       "      <td>0.324964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>XGB</td>\n",
       "      <td>16</td>\n",
       "      <td>[slope, altitude, gdp_2000, gdp_per_capita_200...</td>\n",
       "      <td>-0.006637</td>\n",
       "      <td>0.324769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>XGB</td>\n",
       "      <td>17</td>\n",
       "      <td>[slope, altitude, gdp_2000, gdp_per_capita_200...</td>\n",
       "      <td>-0.006656</td>\n",
       "      <td>0.322632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XGB</td>\n",
       "      <td>18</td>\n",
       "      <td>[slope, altitude, rooting_conditions_index, gd...</td>\n",
       "      <td>-0.006639</td>\n",
       "      <td>0.324464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XGB</td>\n",
       "      <td>19</td>\n",
       "      <td>[slope, altitude, nutrient_retention_index, gd...</td>\n",
       "      <td>-0.006686</td>\n",
       "      <td>0.319525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>XGB</td>\n",
       "      <td>20</td>\n",
       "      <td>[slope, altitude, nutrient_retention_index, gd...</td>\n",
       "      <td>-0.006677</td>\n",
       "      <td>0.320983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>XGB</td>\n",
       "      <td>21</td>\n",
       "      <td>[slope, altitude, rooting_conditions_index, nu...</td>\n",
       "      <td>-0.006617</td>\n",
       "      <td>0.326192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>XGB</td>\n",
       "      <td>22</td>\n",
       "      <td>[slope, altitude, rooting_conditions_index, nu...</td>\n",
       "      <td>-0.006621</td>\n",
       "      <td>0.325979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>XGB</td>\n",
       "      <td>23</td>\n",
       "      <td>[slope, altitude, rooting_conditions_index, ox...</td>\n",
       "      <td>-0.006621</td>\n",
       "      <td>0.325979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>XGB</td>\n",
       "      <td>24</td>\n",
       "      <td>[slope, altitude, workability_index, rooting_c...</td>\n",
       "      <td>-0.006625</td>\n",
       "      <td>0.325545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>XGB</td>\n",
       "      <td>25</td>\n",
       "      <td>[slope, altitude, rooting_conditions_index, pr...</td>\n",
       "      <td>-0.006621</td>\n",
       "      <td>0.326058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>XGB</td>\n",
       "      <td>26</td>\n",
       "      <td>[slope, altitude, rooting_conditions_index, pr...</td>\n",
       "      <td>-0.006617</td>\n",
       "      <td>0.326337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>XGB</td>\n",
       "      <td>27</td>\n",
       "      <td>[slope, altitude, workability_index, rooting_c...</td>\n",
       "      <td>-0.006621</td>\n",
       "      <td>0.325858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>XGB</td>\n",
       "      <td>28</td>\n",
       "      <td>[slope, altitude, workability_index, toxicity_...</td>\n",
       "      <td>-0.006620</td>\n",
       "      <td>0.325847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Poly deg2</td>\n",
       "      <td>5</td>\n",
       "      <td>[rooting_conditions_index, oxygen_availability...</td>\n",
       "      <td>-0.009604</td>\n",
       "      <td>0.018225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Poly deg2</td>\n",
       "      <td>6</td>\n",
       "      <td>[toxicity_index, rooting_conditions_index, tem...</td>\n",
       "      <td>-0.009613</td>\n",
       "      <td>0.017476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Poly deg2</td>\n",
       "      <td>7</td>\n",
       "      <td>[nutrient_availability_index, excess_salts_ind...</td>\n",
       "      <td>-0.009271</td>\n",
       "      <td>0.053359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Poly deg2</td>\n",
       "      <td>8</td>\n",
       "      <td>[minutes_to_market_5m, precip_wet_mth, minutes...</td>\n",
       "      <td>-0.008766</td>\n",
       "      <td>0.104580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Poly deg2</td>\n",
       "      <td>9</td>\n",
       "      <td>[toxicity_index, protected_areas_index, nutrie...</td>\n",
       "      <td>-0.009219</td>\n",
       "      <td>0.058073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Poly deg3</td>\n",
       "      <td>5</td>\n",
       "      <td>[protected_areas_index, nutrient_retention_ind...</td>\n",
       "      <td>-0.009631</td>\n",
       "      <td>0.015671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Poly deg3</td>\n",
       "      <td>6</td>\n",
       "      <td>[protected_areas_index, temp_annualmax, temp_a...</td>\n",
       "      <td>-0.009608</td>\n",
       "      <td>0.017776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Poly deg3</td>\n",
       "      <td>7</td>\n",
       "      <td>[workability_index, nutrient_retention_index, ...</td>\n",
       "      <td>-0.009004</td>\n",
       "      <td>0.080447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Poly deg3</td>\n",
       "      <td>8</td>\n",
       "      <td>[workability_index, toxicity_index, rooting_co...</td>\n",
       "      <td>-0.009300</td>\n",
       "      <td>0.049774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Poly deg3</td>\n",
       "      <td>9</td>\n",
       "      <td>[oxygen_availability_index, nutrient_retention...</td>\n",
       "      <td>-0.009069</td>\n",
       "      <td>0.073137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Poly deg2 w/ interact</td>\n",
       "      <td>5</td>\n",
       "      <td>[nutrient_availability_index, temp_annualmin, ...</td>\n",
       "      <td>-0.009494</td>\n",
       "      <td>0.029081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Poly deg2 w/ interact</td>\n",
       "      <td>6</td>\n",
       "      <td>[workability_index, nutrient_retention_index, ...</td>\n",
       "      <td>-0.009483</td>\n",
       "      <td>0.030499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Poly deg2 w/ interact</td>\n",
       "      <td>7</td>\n",
       "      <td>[toxicity_index, protected_areas_index, nutrie...</td>\n",
       "      <td>-0.009694</td>\n",
       "      <td>0.009087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Poly deg2 w/ interact</td>\n",
       "      <td>8</td>\n",
       "      <td>[workability_index, nutrient_retention_index, ...</td>\n",
       "      <td>-0.009578</td>\n",
       "      <td>0.021014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Poly deg2 w/ interact</td>\n",
       "      <td>9</td>\n",
       "      <td>[altitude, minutes_to_market_5m, precip, altit...</td>\n",
       "      <td>-0.008435</td>\n",
       "      <td>0.138411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Poly deg3 w/ interact</td>\n",
       "      <td>5</td>\n",
       "      <td>[workability_index, nutrient_retention_index, ...</td>\n",
       "      <td>-0.009374</td>\n",
       "      <td>0.041473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Poly deg3 w/ interact</td>\n",
       "      <td>6</td>\n",
       "      <td>[workability_index, nutrient_retention_index, ...</td>\n",
       "      <td>-0.009114</td>\n",
       "      <td>0.069369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Poly deg3 w/ interact</td>\n",
       "      <td>7</td>\n",
       "      <td>[workability_index, oxygen_availability_index,...</td>\n",
       "      <td>-0.009062</td>\n",
       "      <td>0.074636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Poly deg3 w/ interact</td>\n",
       "      <td>8</td>\n",
       "      <td>[workability_index, rooting_conditions_index, ...</td>\n",
       "      <td>-0.009441</td>\n",
       "      <td>0.034882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Poly deg3 w/ interact</td>\n",
       "      <td>9</td>\n",
       "      <td>[workability_index, toxicity_index, protected_...</td>\n",
       "      <td>-0.009570</td>\n",
       "      <td>0.021969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp_2000, temp_avg, precip, pixel_id_float, l...</td>\n",
       "      <td>-1.099954</td>\n",
       "      <td>0.401847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model num_features  \\\n",
       "0       Linear Regression            5   \n",
       "1       Linear Regression            6   \n",
       "2       Linear Regression            7   \n",
       "3       Linear Regression            8   \n",
       "4       Linear Regression            9   \n",
       "5       Linear Regression           10   \n",
       "6       Linear Regression           11   \n",
       "7       Linear Regression           12   \n",
       "8       Linear Regression           13   \n",
       "9       Linear Regression           14   \n",
       "10      Linear Regression           15   \n",
       "11      Linear Regression           16   \n",
       "12      Linear Regression           17   \n",
       "13      Linear Regression           18   \n",
       "14      Linear Regression           19   \n",
       "15                    XGB            5   \n",
       "16                    XGB            6   \n",
       "17                    XGB            7   \n",
       "18                    XGB            8   \n",
       "19                    XGB            9   \n",
       "20                    XGB           10   \n",
       "21                    XGB           11   \n",
       "22                    XGB           12   \n",
       "23                    XGB           13   \n",
       "24                    XGB           14   \n",
       "25                    XGB           15   \n",
       "26                    XGB           16   \n",
       "27                    XGB           17   \n",
       "28                    XGB           18   \n",
       "29                    XGB           19   \n",
       "30                    XGB           20   \n",
       "31                    XGB           21   \n",
       "32                    XGB           22   \n",
       "33                    XGB           23   \n",
       "34                    XGB           24   \n",
       "35                    XGB           25   \n",
       "36                    XGB           26   \n",
       "37                    XGB           27   \n",
       "38                    XGB           28   \n",
       "39              Poly deg2            5   \n",
       "40              Poly deg2            6   \n",
       "41              Poly deg2            7   \n",
       "42              Poly deg2            8   \n",
       "43              Poly deg2            9   \n",
       "44              Poly deg3            5   \n",
       "45              Poly deg3            6   \n",
       "46              Poly deg3            7   \n",
       "47              Poly deg3            8   \n",
       "48              Poly deg3            9   \n",
       "49  Poly deg2 w/ interact            5   \n",
       "50  Poly deg2 w/ interact            6   \n",
       "51  Poly deg2 w/ interact            7   \n",
       "52  Poly deg2 w/ interact            8   \n",
       "53  Poly deg2 w/ interact            9   \n",
       "54  Poly deg3 w/ interact            5   \n",
       "55  Poly deg3 w/ interact            6   \n",
       "56  Poly deg3 w/ interact            7   \n",
       "57  Poly deg3 w/ interact            8   \n",
       "58  Poly deg3 w/ interact            9   \n",
       "59                    XGB            5   \n",
       "\n",
       "                                             Features       MSE        R2  \n",
       "0   [toxicity_index, rooting_conditions_index, nut... -0.008604  0.121383  \n",
       "1   [toxicity_index, rooting_conditions_index, nut... -0.008512  0.131148  \n",
       "2   [toxicity_index, rooting_conditions_index, nut... -0.008494  0.132957  \n",
       "3   [toxicity_index, rooting_conditions_index, nut... -0.008493  0.133093  \n",
       "4   [toxicity_index, rooting_conditions_index, nut... -0.008494  0.132958  \n",
       "5   [toxicity_index, rooting_conditions_index, nut... -0.008215  0.161261  \n",
       "6   [toxicity_index, rooting_conditions_index, nut... -0.008182  0.164579  \n",
       "7   [toxicity_index, rooting_conditions_index, nut... -0.008184  0.164461  \n",
       "8   [toxicity_index, rooting_conditions_index, nut... -0.008175  0.165415  \n",
       "9   [toxicity_index, rooting_conditions_index, pro... -0.008175  0.165405  \n",
       "10  [workability_index, toxicity_index, rooting_co... -0.008143  0.168819  \n",
       "11  [workability_index, toxicity_index, rooting_co... -0.007957  0.188289  \n",
       "12  [slope, toxicity_index, rooting_conditions_ind... -0.007957  0.188378  \n",
       "13  [workability_index, toxicity_index, rooting_co... -0.007958  0.188228  \n",
       "14  [slope, workability_index, toxicity_index, roo... -0.007959  0.188201  \n",
       "15  [slope, temp_avg, temp_isothermality, precip, ... -0.007140  0.272384  \n",
       "16  [slope, temp_isothermality, temp_seasonality, ... -0.007153  0.271551  \n",
       "17  [slope, gdp_2000, temp_avg, temp_isothermality... -0.006988  0.288531  \n",
       "18  [slope, gdp_2000, gdp_per_capita_2000_5m, temp... -0.006850  0.303025  \n",
       "19  [slope, gdp_2000, gdp_per_capita_2000_5m, temp... -0.006735  0.314144  \n",
       "20  [slope, altitude, gdp_2000, gpw_population, te... -0.006765  0.312061  \n",
       "21  [slope, altitude, gdp_2000, gdp_per_capita_200... -0.006610  0.327771  \n",
       "22  [slope, altitude, gdp_2000, gdp_per_capita_200... -0.006644  0.323681  \n",
       "23  [slope, altitude, gdp_2000, gdp_per_capita_200... -0.006611  0.327568  \n",
       "24  [slope, altitude, gdp_2000, gdp_per_capita_200... -0.006600  0.328831  \n",
       "25  [slope, altitude, gdp_2000, gdp_per_capita_200... -0.006632  0.324964  \n",
       "26  [slope, altitude, gdp_2000, gdp_per_capita_200... -0.006637  0.324769  \n",
       "27  [slope, altitude, gdp_2000, gdp_per_capita_200... -0.006656  0.322632  \n",
       "28  [slope, altitude, rooting_conditions_index, gd... -0.006639  0.324464  \n",
       "29  [slope, altitude, nutrient_retention_index, gd... -0.006686  0.319525  \n",
       "30  [slope, altitude, nutrient_retention_index, gd... -0.006677  0.320983  \n",
       "31  [slope, altitude, rooting_conditions_index, nu... -0.006617  0.326192  \n",
       "32  [slope, altitude, rooting_conditions_index, nu... -0.006621  0.325979  \n",
       "33  [slope, altitude, rooting_conditions_index, ox... -0.006621  0.325979  \n",
       "34  [slope, altitude, workability_index, rooting_c... -0.006625  0.325545  \n",
       "35  [slope, altitude, rooting_conditions_index, pr... -0.006621  0.326058  \n",
       "36  [slope, altitude, rooting_conditions_index, pr... -0.006617  0.326337  \n",
       "37  [slope, altitude, workability_index, rooting_c... -0.006621  0.325858  \n",
       "38  [slope, altitude, workability_index, toxicity_... -0.006620  0.325847  \n",
       "39  [rooting_conditions_index, oxygen_availability... -0.009604  0.018225  \n",
       "40  [toxicity_index, rooting_conditions_index, tem... -0.009613  0.017476  \n",
       "41  [nutrient_availability_index, excess_salts_ind... -0.009271  0.053359  \n",
       "42  [minutes_to_market_5m, precip_wet_mth, minutes... -0.008766  0.104580  \n",
       "43  [toxicity_index, protected_areas_index, nutrie... -0.009219  0.058073  \n",
       "44  [protected_areas_index, nutrient_retention_ind... -0.009631  0.015671  \n",
       "45  [protected_areas_index, temp_annualmax, temp_a... -0.009608  0.017776  \n",
       "46  [workability_index, nutrient_retention_index, ... -0.009004  0.080447  \n",
       "47  [workability_index, toxicity_index, rooting_co... -0.009300  0.049774  \n",
       "48  [oxygen_availability_index, nutrient_retention... -0.009069  0.073137  \n",
       "49  [nutrient_availability_index, temp_annualmin, ... -0.009494  0.029081  \n",
       "50  [workability_index, nutrient_retention_index, ... -0.009483  0.030499  \n",
       "51  [toxicity_index, protected_areas_index, nutrie... -0.009694  0.009087  \n",
       "52  [workability_index, nutrient_retention_index, ... -0.009578  0.021014  \n",
       "53  [altitude, minutes_to_market_5m, precip, altit... -0.008435  0.138411  \n",
       "54  [workability_index, nutrient_retention_index, ... -0.009374  0.041473  \n",
       "55  [workability_index, nutrient_retention_index, ... -0.009114  0.069369  \n",
       "56  [workability_index, oxygen_availability_index,... -0.009062  0.074636  \n",
       "57  [workability_index, rooting_conditions_index, ... -0.009441  0.034882  \n",
       "58  [workability_index, toxicity_index, protected_... -0.009570  0.021969  \n",
       "59  [gdp_2000, temp_avg, precip, pixel_id_float, l... -1.099954  0.401847  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated functions to make regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_regression(regression,dataframe):\n",
    "    ##Must make dummies for categorical variable climate_zone\n",
    "    # dataframe = pd.get_dummies(dataframe, columns=['climate_zone'])\n",
    "    # Or just drop column if don't want dummies: x = x.drop(['climate_zone'], axis=1)\n",
    "\n",
    "    x = dataframe.drop(['calories_per_ha'], axis=1)\n",
    "    y = dataframe['calories_per_ha']\n",
    "\n",
    "    ### Cross validation scores\n",
    "    r2_scores = cross_val_score(regression, x, y, cv=10,scoring='r2')\n",
    "    mse_scores = cross_val_score(regression, x, y, cv=10, scoring='neg_mean_squared_error')\n",
    "    mae_scores = cross_val_score(regression, x, y, cv=10, scoring='neg_mean_absolute_error')\n",
    "    \n",
    "    return [np.mean(r2_scores),np.mean(mse_scores),np.mean(mae_scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_predictions(regression,dataframe,show_df=True,show_plot=True):\n",
    "    x = dataframe.drop(['calories_per_ha','climate_zones'], axis=1)\n",
    "    y = dataframe['calories_per_ha']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "    reg = regression.fit(X_train, y_train)\n",
    "    y_predicted = reg.predict(X_test)\n",
    "\n",
    "    compare = pd.DataFrame()\n",
    "    compare['y_test'] = y_test\n",
    "    compare['predicted'] = y_predicted\n",
    "\n",
    "    if show_plot == True:\n",
    "        ax = compare.plot.scatter(x='y_test',y='predicted',s=0.5)\n",
    "        ax.plot(ax.get_xlim(), ax.get_xlim(), ls=\"--\", c=\".3\")\n",
    "        \n",
    "    return compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def fxn():\n",
    "    warnings.warn(\"future\", FutureWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['calories_per_ha', 'slope', 'altitude', 'workability_index',\n",
       "       'toxicity_index', 'rooting_conditions_index', 'protected_areas_index',\n",
       "       'oxygen_availability_index', 'nutrient_retention_index',\n",
       "       'nutrient_availability_index', 'excess_salts_index', 'gdp',\n",
       "       'gdp_per_capita', 'min_to_market', 'gpw_population', 'temp_avg',\n",
       "       'temp_diurnalrange', 'temp_isothermality', 'temp_seasonality',\n",
       "       'temp_annualmax', 'temp_annualmin', 'temp_annualrange', 'precip',\n",
       "       'precip_wet_mth', 'precip_dry_mth', 'precip_seasonality',\n",
       "       'pixel_id_float', 'land_mask', 'lat', 'lon', 'climatezone_Af',\n",
       "       'climatezone_Am', 'climatezone_Aw', 'climatezone_BSh',\n",
       "       'climatezone_BSk', 'climatezone_BWh', 'climatezone_BWk',\n",
       "       'climatezone_Cfa', 'climatezone_Cfb', 'climatezone_Cfc',\n",
       "       'climatezone_Csa', 'climatezone_Csb', 'climatezone_Csc',\n",
       "       'climatezone_Cwa', 'climatezone_Cwb', 'climatezone_Cwc',\n",
       "       'climatezone_Dfa', 'climatezone_Dfb', 'climatezone_Dfc',\n",
       "       'climatezone_Dfd', 'climatezone_Dsa', 'climatezone_Dsb',\n",
       "       'climatezone_Dsc', 'climatezone_Dsd', 'climatezone_Dwa',\n",
       "       'climatezone_Dwb', 'climatezone_Dwc', 'climatezone_Dwd',\n",
       "       'climatezone_EF', 'climatezone_ET', 'log_gdp_per_capita',\n",
       "       'log_altitude', 'log_min_to_market', 'log_gpw_population'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning XGB Parameters\n",
    "\n",
    "\n",
    "\n",
    "##### Parameters to tune (with = default value): \n",
    "* max_depth=3,\n",
    "* learning_rate=0.1, --> explore in step 1 -- typically values in 0.01-0.2\n",
    "* n_estimators=100, --> explore in step 1\n",
    "\n",
    "* min_child_weight=1 --> Used to control over-fitting should be tuned using cv\n",
    "\n",
    "\n",
    "* ??? max_depth = 6 --> tune btw 3-10 using cv\n",
    "* ??? subsample = 1 -->  0.5-1 (higher: overfit)\n",
    "\n",
    "silent=True, objective='reg:linear', \n",
    "\n",
    "booster='gbtree' ALSO TRY gblinear\n",
    "\n",
    "\n",
    "0.5-1\n",
    "\n",
    ", gamma=0,\n",
    "\n",
    "* max_delta_step=0 --> generally not used.\n",
    "###### Other function parameters \n",
    "* n_jobs=1, nthread=None --> for parallelization\n",
    "subsample=1,\n",
    "\n",
    "colsample_bytree=1, --> 0.5-1\n",
    "colsample_bylevel=1, --> no need to tune, subsample and colsample_bytree will do the job\n",
    "\n",
    "reg_alpha=0, --> L1 regularization term on weight (analogous to Lasso regression). To make faster if high dim\n",
    "reg_lambda=1, --> L2 regularization term on weights (analogous to Ridge regression). not critical to tune\n",
    "\n",
    "scale_pos_weight=1, --> (class imbalance) not sure\n",
    "\n",
    "base_score=0.5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['booster'] = df['booster'].apply(lambda x: x='gbtree' if x==np.nan else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_tuning = pd.DataFrame(columns=['Model','num_features','Features','MSE','R2','learning_rate','n_estimators'])\n",
    "\n",
    "## is a parameter = nan --> means default value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_tuning2 = pd.DataFrame(columns=['Model','num_features','Features','MSE','R2','learning_rate','n_estimators'])\n",
    "\n",
    "## is a parameter = nan --> means default value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.05 -- n_estimators = 40  -- \n",
      "    with all features...\n",
      "    R2_score : -2.089662843804917\n",
      "    MSE_score : -5.497891785362941\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : -2.1137687302130006\n",
      "    MSE_score : -5.540515274035159\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.05 -- n_estimators = 55  -- \n",
      "    with all features...\n",
      "    R2_score : -0.15765197131771708\n",
      "    MSE_score : -2.066127521164086\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : -0.17693431412043975\n",
      "    MSE_score : -2.0999350521574263\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.05 -- n_estimators = 70  -- \n",
      "    with all features...\n",
      "    R2_score : 0.2695568240841067\n",
      "    MSE_score : -1.3084654633817094\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.24682794796441362\n",
      "    MSE_score : -1.3480304976032282\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.05 -- n_estimators = 85  -- \n",
      "    with all features...\n",
      "    R2_score : 0.3692546887871212\n",
      "    MSE_score : -1.1321555945526434\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.32959599838890946\n",
      "    MSE_score : -1.2019140554971757\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.05 -- n_estimators = 100  -- \n",
      "    with all features...\n",
      "    R2_score : 0.39543406979017115\n",
      "    MSE_score : -1.0860957148106405\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.37487769971103746\n",
      "    MSE_score : -1.1220867679144997\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.1 -- n_estimators = 40  -- \n",
      "    with all features...\n",
      "    R2_score : 0.3568755734299513\n",
      "    MSE_score : -1.1540865016318491\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.33138836313537007\n",
      "    MSE_score : -1.1987909292009942\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.1 -- n_estimators = 55  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4024393077849405\n",
      "    MSE_score : -1.0736631189783818\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.3684020838923766\n",
      "    MSE_score : -1.1334497808516975\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.1 -- n_estimators = 70  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4152563784378427\n",
      "    MSE_score : -1.0510276712586915\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.3809575192703091\n",
      "    MSE_score : -1.1116828912475083\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.1 -- n_estimators = 85  -- \n",
      "    with all features...\n",
      "    R2_score : 0.42385247395888526\n",
      "    MSE_score : -1.0355248404675959\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.39118833435287004\n",
      "    MSE_score : -1.0934908153792842\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.1 -- n_estimators = 100  -- \n",
      "    with all features...\n",
      "    R2_score : 0.42963066019295554\n",
      "    MSE_score : -1.025111013372745\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.38952293352533374\n",
      "    MSE_score : -1.0963676539068627\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.15 -- n_estimators = 40  -- \n",
      "    with all features...\n",
      "    R2_score : 0.40751395216220654\n",
      "    MSE_score : -1.0647974257943162\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.37768991407704416\n",
      "    MSE_score : -1.1169088395379188\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.15 -- n_estimators = 55  -- \n",
      "    with all features...\n",
      "    R2_score : 0.42339808903564274\n",
      "    MSE_score : -1.03660639731994\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.37872615797946263\n",
      "    MSE_score : -1.115428914797226\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.15 -- n_estimators = 70  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4334264115038796\n",
      "    MSE_score : -1.018474930134619\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.4245190117952139\n",
      "    MSE_score : -1.0323065439422854\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.15 -- n_estimators = 85  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4408841688778784\n",
      "    MSE_score : -1.0049009332531038\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.40569810371729104\n",
      "    MSE_score : -1.0679044582509585\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.15 -- n_estimators = 100  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4478456729018415\n",
      "    MSE_score : -0.992542895942463\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.41457665127855803\n",
      "    MSE_score : -1.0492828135790908\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.2 -- n_estimators = 40  -- \n",
      "    with all features...\n",
      "    R2_score : 0.41925708016665186\n",
      "    MSE_score : -1.0433175953261913\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.38768868857084987\n",
      "    MSE_score : -1.0997533705864166\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.2 -- n_estimators = 55  -- \n",
      "    with all features...\n",
      "    R2_score : 0.43077126464876503\n",
      "    MSE_score : -1.0227604605363927\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.3969462517476524\n",
      "    MSE_score : -1.0830791634372126\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.2 -- n_estimators = 70  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4416081987218883\n",
      "    MSE_score : -1.003162141125355\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.3956064139018287\n",
      "    MSE_score : -1.0851938247561208\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.2 -- n_estimators = 85  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4493115637278061\n",
      "    MSE_score : -0.9893101680908662\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.4229844017831684\n",
      "    MSE_score : -1.0361121567436804\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.2 -- n_estimators = 100  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4548195624605576\n",
      "    MSE_score : -0.9791243117655654\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.4292635093682267\n",
      "    MSE_score : -1.024542445992736\n",
      "    ... done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Â Testing XGBoost with params (RESULTS BELOW WITH CLIMZONES)\n",
    "\n",
    "model = 'XGB'\n",
    "## First choose: learning_rate, n_estimators\n",
    "for learning_rate in [0.05, 0.1, 0.15, 0.2]:\n",
    "    for n_estimators in [40,55,70,85,100]:\n",
    "        print('Running XGBoost with params:')\n",
    "        print(' -- Learning Rate = ' + str(learning_rate) +' -- n_estimators = ' + str(n_estimators) + '  -- ')\n",
    "        \n",
    "        regression = xgb.XGBRegressor(learning_rate = learning_rate,n_estimators = n_estimators)\n",
    "\n",
    "\n",
    "\n",
    "        # Doing it will all features\n",
    "        print('    with all features...')\n",
    "        num_features = len(df.columns)-2\n",
    "        Features = 'All w/ climzones'\n",
    "        \n",
    "        scores = do_regression(regression,df)\n",
    "\n",
    "        print('    R2_score : '+str(scores[0]))\n",
    "        print('    MSE_score : '+str(scores[1]))\n",
    "        \n",
    "        R2_score = scores[0]\n",
    "        MSE_score = scores[1]\n",
    "        \n",
    "        xgb_tuning = xgb_tuning.append({'Model': model,\n",
    "                                        'num_features':len(df.columns)-1,'Features':'All w/ climzones',\n",
    "                                        'learning_rate':learning_rate,'n_estimators':n_estimators,\n",
    "                                        'R2':R2_score,'MSE':MSE_score},ignore_index=True)\n",
    "\n",
    "        print('    ... done')\n",
    "\n",
    "        # Iterate over â  numbers of features\n",
    "        for num_features in range (5,6):\n",
    "\n",
    "            print('    with '+str(num_features)+ ' features ...')\n",
    "\n",
    "            ## RFE - Features selection\n",
    "            selector = RFE(regression, num_features, step=1)\n",
    "\n",
    "            x = df.drop(['calories_per_ha'], axis=1) ## TODO climate_zones encode One Hot Encoder\n",
    "            y = df['calories_per_ha']\n",
    "            X, X_test, Y, Y_test = train_test_split(x, y)\n",
    "\n",
    "            X_RFE = selector.fit_transform(X,Y)\n",
    "\n",
    "            features_selected = [X.columns[feature_pos] for feature_pos in selector.get_support(indices=True)]\n",
    "            features_selected.append('calories_per_ha')\n",
    "            scores = do_regression(regression,df[features_selected])\n",
    "            print('    R2_score : '+str(scores[0]))\n",
    "            print('    MSE_score : '+str(scores[1]))\n",
    "            \n",
    "            R2_score = scores[0]\n",
    "            MSE_score = scores[1]\n",
    "            xgb_tuning = xgb_tuning.append({'Model': model,\n",
    "                                        'num_features':num_features,'Features':features_selected,\n",
    "                                        'learning_rate':learning_rate,'n_estimators':n_estimators,\n",
    "                                        'R2':R2_score,'MSE':MSE_score},ignore_index=True)\n",
    "    \n",
    "    \n",
    "            print('    ... done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.1 -- n_estimators = 60  -- \n",
      "    with all features...\n",
      "    R2_score : 0.40708732247447327\n",
      "    MSE_score : -1.06537790771409\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.38879883315835057\n",
      "    MSE_score : -1.0970218169403638\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.1 -- n_estimators = 71  -- \n",
      "    with all features...\n",
      "    R2_score : 0.41561154433024344\n",
      "    MSE_score : -1.0504058484902052\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.38783847459227305\n",
      "    MSE_score : -1.0984002813232188\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.1 -- n_estimators = 80  -- \n",
      "    with all features...\n",
      "    R2_score : 0.42125333191441355\n",
      "    MSE_score : -1.040193863891528\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.3930622487968773\n",
      "    MSE_score : -1.0889968493221769\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.1 -- n_estimators = 90  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4258992423166525\n",
      "    MSE_score : -1.0317989604848197\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.3817638774204258\n",
      "    MSE_score : -1.110831820810618\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.1 -- n_estimators = 101  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4300739899863812\n",
      "    MSE_score : -1.0243021934133059\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.4234771000905204\n",
      "    MSE_score : -1.0361294355703323\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.1 -- n_estimators = 110  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4343714608578056\n",
      "    MSE_score : -1.0164809264442618\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.39495842015090116\n",
      "    MSE_score : -1.0858167306474633\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.1 -- n_estimators = 120  -- \n",
      "    with all features...\n",
      "    R2_score : 0.43685169226754317\n",
      "    MSE_score : -1.0121045292405633\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.3849476074290399\n",
      "    MSE_score : -1.1046214115256088\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.15 -- n_estimators = 60  -- \n",
      "    with all features...\n",
      "    R2_score : 0.42721788691034784\n",
      "    MSE_score : -1.0299639660581248\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.38973064333934415\n",
      "    MSE_score : -1.095277365235829\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.15 -- n_estimators = 71  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4336406456891164\n",
      "    MSE_score : -1.017978130514579\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.3985025743148065\n",
      "    MSE_score : -1.080707586452219\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.15 -- n_estimators = 80  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4382003537776183\n",
      "    MSE_score : -1.0097415823109113\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.3923606363815205\n",
      "    MSE_score : -1.0911578377707867\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.15 -- n_estimators = 90  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4428063337771092\n",
      "    MSE_score : -1.0015330364775326\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.40671920273976847\n",
      "    MSE_score : -1.0653653687664635\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.15 -- n_estimators = 101  -- \n",
      "    with all features...\n",
      "    R2_score : 0.44839292362411315\n",
      "    MSE_score : -0.9916105869093682\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.40890695577414854\n",
      "    MSE_score : -1.0604964387434332\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.15 -- n_estimators = 110  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4514801883731973\n",
      "    MSE_score : -0.9859845279098826\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.4119281320600262\n",
      "    MSE_score : -1.055133823121589\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.15 -- n_estimators = 120  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4530490224128723\n",
      "    MSE_score : -0.9831599338012941\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.4274562041803027\n",
      "    MSE_score : -1.0262297594533656\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.2 -- n_estimators = 60  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4356356831510776\n",
      "    MSE_score : -1.0139897313689612\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.3941409741109565\n",
      "    MSE_score : -1.0885506918262142\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.2 -- n_estimators = 71  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4418106113000217\n",
      "    MSE_score : -1.0029035314692434\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.412816484932052\n",
      "    MSE_score : -1.0542560153872862\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.2 -- n_estimators = 80  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4458011520659218\n",
      "    MSE_score : -0.9957604119254982\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.4059902167842998\n",
      "    MSE_score : -1.0675455140585328\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.2 -- n_estimators = 90  -- \n",
      "    with all features...\n",
      "    R2_score : 0.45179597189256004\n",
      "    MSE_score : -0.984815594636807\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.41465993058646067\n",
      "    MSE_score : -1.051725860068222\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.2 -- n_estimators = 101  -- \n",
      "    with all features...\n",
      "    R2_score : 0.45471655354047186\n",
      "    MSE_score : -0.9792707610897992\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.4174577578838181\n",
      "    MSE_score : -1.0467476740889627\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.2 -- n_estimators = 110  -- \n",
      "    with all features...\n",
      "    R2_score : 0.458428350898288\n",
      "    MSE_score : -0.9724061389634324\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.4318686905628816\n",
      "    MSE_score : -1.0195709447956283\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.2 -- n_estimators = 120  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4600064459482165\n",
      "    MSE_score : -0.9695387326119447\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.4169121772936317\n",
      "    MSE_score : -1.0481422190750367\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.25 -- n_estimators = 60  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4443164101374986\n",
      "    MSE_score : -0.9982247728466784\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.3993248389650063\n",
      "    MSE_score : -1.0791271764291428\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.25 -- n_estimators = 71  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4477651977939131\n",
      "    MSE_score : -0.9923899349948165\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.40375381190871673\n",
      "    MSE_score : -1.071298761941471\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.25 -- n_estimators = 80  -- \n",
      "    with all features...\n",
      "    R2_score : 0.44997684884447997\n",
      "    MSE_score : -0.9883363067376291\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.41788460792500803\n",
      "    MSE_score : -1.0462762827114869\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.25 -- n_estimators = 90  -- \n",
      "    with all features...\n",
      "    R2_score : 0.45465792110801306\n",
      "    MSE_score : -0.9798371113714881\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.4171930881522017\n",
      "    MSE_score : -1.0478729368428046\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.25 -- n_estimators = 101  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4593600054348079\n",
      "    MSE_score : -0.9712112890591822\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.4307827481363605\n",
      "    MSE_score : -1.0203926106538521\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.25 -- n_estimators = 110  -- \n",
      "    with all features...\n",
      "    R2_score : 0.461211483988634\n",
      "    MSE_score : -0.9679798417424305\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.4173150825690272\n",
      "    MSE_score : -1.0445330211570125\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.25 -- n_estimators = 120  -- \n",
      "    with all features...\n",
      "    R2_score : 0.46141050714819515\n",
      "    MSE_score : -0.9676346741748298\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.4218720297681037\n",
      "    MSE_score : -1.036445598282548\n",
      "    ... done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Â Testing XGBoost with params (RESULTS BELOW WITH CLIMZONES) (Same as above)\n",
    "\n",
    "model = 'XGB'\n",
    "## First choose: learning_rate, n_estimators\n",
    "for learning_rate in [0.1, 0.15, 0.2,0.25]:\n",
    "    for n_estimators in [60,71,80,90,101,110,120]:\n",
    "        print('Running XGBoost with params:')\n",
    "        print(' -- Learning Rate = ' + str(learning_rate) +' -- n_estimators = ' + str(n_estimators) + '  -- ')\n",
    "        \n",
    "        regression = xgb.XGBRegressor(learning_rate = learning_rate,n_estimators = n_estimators)\n",
    "\n",
    "\n",
    "\n",
    "        # Doing it will all features\n",
    "        print('    with all features...')\n",
    "        num_features = len(df.columns)-2\n",
    "        Features = 'All w/ climzones'\n",
    "        \n",
    "        scores = do_regression(regression,df)\n",
    "\n",
    "        print('    R2_score : '+str(scores[0]))\n",
    "        print('    MSE_score : '+str(scores[1]))\n",
    "        \n",
    "        R2_score = scores[0]\n",
    "        MSE_score = scores[1]\n",
    "        \n",
    "        xgb_tuning2 = xgb_tuning2.append({'Model': model,\n",
    "                                        'num_features':len(df.columns)-1,'Features':'All w/ climzones',\n",
    "                                        'learning_rate':learning_rate,'n_estimators':n_estimators,\n",
    "                                        'R2':R2_score,'MSE':MSE_score},ignore_index=True)\n",
    "\n",
    "        print('    ... done')\n",
    "\n",
    "        # Iterate over â  numbers of features\n",
    "        for num_features in range (5,6):\n",
    "\n",
    "            print('    with '+str(num_features)+ ' features ...')\n",
    "\n",
    "            ## RFE - Features selection\n",
    "            selector = RFE(regression, num_features, step=1)\n",
    "\n",
    "            x = df.drop(['calories_per_ha'], axis=1) ## TODO climate_zones encode One Hot Encoder\n",
    "            y = df['calories_per_ha']\n",
    "            X, X_test, Y, Y_test = train_test_split(x, y)\n",
    "\n",
    "            X_RFE = selector.fit_transform(X,Y)\n",
    "\n",
    "            features_selected = [X.columns[feature_pos] for feature_pos in selector.get_support(indices=True)]\n",
    "            features_selected.append('calories_per_ha')\n",
    "            scores = do_regression(regression,df[features_selected])\n",
    "            print('    R2_score : '+str(scores[0]))\n",
    "            print('    MSE_score : '+str(scores[1]))\n",
    "            \n",
    "            R2_score = scores[0]\n",
    "            MSE_score = scores[1]\n",
    "            xgb_tuning2 = xgb_tuning2.append({'Model': model,\n",
    "                                        'num_features':num_features,'Features':features_selected,\n",
    "                                        'learning_rate':learning_rate,'n_estimators':n_estimators,\n",
    "                                        'R2':R2_score,'MSE':MSE_score},ignore_index=True)\n",
    "    \n",
    "    \n",
    "            print('    ... done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_R2_2params('n_estimators', 'learning_rate', xgb_tuning2[xgb_tuning2['num_features']==63])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_R2_2params(param_x, param_color, xgb_tuning,scatter=False):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,5))\n",
    "\n",
    "\n",
    "    palette = plt.get_cmap('Set2')\n",
    "    num=0\n",
    "    for learning_rate in xgb_tuning.learning_rate.unique():\n",
    "        num+=1\n",
    "        x = (xgb_tuning[xgb_tuning[param_color]==learning_rate][param_x])\n",
    "        y = (xgb_tuning[xgb_tuning[param_color]==learning_rate]['R2'])\n",
    "        #labels= (xgb_tuning[xgb_tuning[param_color]==learning_rate][param_color])\n",
    "        if scatter == False:\n",
    "            P = plt.plot(x,y, marker='.',color=palette(num), linewidth=2, alpha=0.9,\n",
    "                 label=('learning rate: ' +str(learning_rate)))\n",
    "        if scatter == True:\n",
    "            P = plt.scatter(x,y, marker='o',color=palette(num),\n",
    "                 label=('learning rate: ' +str(learning_rate)))\n",
    "        \n",
    "    plt.legend(loc=2, ncol=1)\n",
    "    plt.title((\"Tuning XGB: \"+ param_x +\" and \"+param_color), loc='left', fontsize=18, fontweight=0, color='black')\n",
    "\n",
    "    plt.xlabel(param_x)\n",
    "    plt.ylabel(\"R2\")\n",
    "    \n",
    "    # Y lim\n",
    "    if scatter == False:\n",
    "        P[0].axes.set_ylim(0.3,0.5)\n",
    "    if scatter == True:\n",
    "        P.axes.set_ylim(0.3,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>num_features</th>\n",
       "      <th>Features</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-5.497892</td>\n",
       "      <td>-2.089663</td>\n",
       "      <td>0.05</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp, gdp_per_capita, gpw_population, precip, ...</td>\n",
       "      <td>-5.540515</td>\n",
       "      <td>-2.113769</td>\n",
       "      <td>0.05</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-2.066128</td>\n",
       "      <td>-0.157652</td>\n",
       "      <td>0.05</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp, gpw_population, temp_isothermality, prec...</td>\n",
       "      <td>-2.099935</td>\n",
       "      <td>-0.176934</td>\n",
       "      <td>0.05</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.308465</td>\n",
       "      <td>0.269557</td>\n",
       "      <td>0.05</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp, gpw_population, temp_seasonality, pixel_...</td>\n",
       "      <td>-1.348030</td>\n",
       "      <td>0.246828</td>\n",
       "      <td>0.05</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.132156</td>\n",
       "      <td>0.369255</td>\n",
       "      <td>0.05</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp, temp_isothermality, precip, pixel_id_flo...</td>\n",
       "      <td>-1.201914</td>\n",
       "      <td>0.329596</td>\n",
       "      <td>0.05</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.086096</td>\n",
       "      <td>0.395434</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gpw_population, temp_seasonality, precip, pix...</td>\n",
       "      <td>-1.122087</td>\n",
       "      <td>0.374878</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.154087</td>\n",
       "      <td>0.356876</td>\n",
       "      <td>0.10</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp_per_capita, gpw_population, temp_isotherm...</td>\n",
       "      <td>-1.198791</td>\n",
       "      <td>0.331388</td>\n",
       "      <td>0.10</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.073663</td>\n",
       "      <td>0.402439</td>\n",
       "      <td>0.10</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp, temp_isothermality, precip, pixel_id_flo...</td>\n",
       "      <td>-1.133450</td>\n",
       "      <td>0.368402</td>\n",
       "      <td>0.10</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.051028</td>\n",
       "      <td>0.415256</td>\n",
       "      <td>0.10</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp, temp_isothermality, precip, pixel_id_flo...</td>\n",
       "      <td>-1.111683</td>\n",
       "      <td>0.380958</td>\n",
       "      <td>0.10</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.035525</td>\n",
       "      <td>0.423852</td>\n",
       "      <td>0.10</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp, temp_isothermality, precip, pixel_id_flo...</td>\n",
       "      <td>-1.093491</td>\n",
       "      <td>0.391188</td>\n",
       "      <td>0.10</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.025111</td>\n",
       "      <td>0.429631</td>\n",
       "      <td>0.10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[temp_avg, temp_seasonality, precip, pixel_id_...</td>\n",
       "      <td>-1.096368</td>\n",
       "      <td>0.389523</td>\n",
       "      <td>0.10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.064797</td>\n",
       "      <td>0.407514</td>\n",
       "      <td>0.15</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp, temp_isothermality, precip, pixel_id_flo...</td>\n",
       "      <td>-1.116909</td>\n",
       "      <td>0.377690</td>\n",
       "      <td>0.15</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.036606</td>\n",
       "      <td>0.423398</td>\n",
       "      <td>0.15</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[temp_avg, temp_isothermality, precip, pixel_i...</td>\n",
       "      <td>-1.115429</td>\n",
       "      <td>0.378726</td>\n",
       "      <td>0.15</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.018475</td>\n",
       "      <td>0.433426</td>\n",
       "      <td>0.15</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp, gpw_population, temp_seasonality, pixel_...</td>\n",
       "      <td>-1.032307</td>\n",
       "      <td>0.424519</td>\n",
       "      <td>0.15</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.004901</td>\n",
       "      <td>0.440884</td>\n",
       "      <td>0.15</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp_per_capita, temp_isothermality, precip, p...</td>\n",
       "      <td>-1.067904</td>\n",
       "      <td>0.405698</td>\n",
       "      <td>0.15</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-0.992543</td>\n",
       "      <td>0.447846</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp_per_capita, temp_avg, temp_seasonality, p...</td>\n",
       "      <td>-1.049283</td>\n",
       "      <td>0.414577</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.043318</td>\n",
       "      <td>0.419257</td>\n",
       "      <td>0.20</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp, temp_isothermality, precip, pixel_id_flo...</td>\n",
       "      <td>-1.099753</td>\n",
       "      <td>0.387689</td>\n",
       "      <td>0.20</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.022760</td>\n",
       "      <td>0.430771</td>\n",
       "      <td>0.20</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp_per_capita, temp_isothermality, precip, p...</td>\n",
       "      <td>-1.083079</td>\n",
       "      <td>0.396946</td>\n",
       "      <td>0.20</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.003162</td>\n",
       "      <td>0.441608</td>\n",
       "      <td>0.20</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[temp_isothermality, temp_seasonality, precip,...</td>\n",
       "      <td>-1.085194</td>\n",
       "      <td>0.395606</td>\n",
       "      <td>0.20</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-0.989310</td>\n",
       "      <td>0.449312</td>\n",
       "      <td>0.20</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp_per_capita, temp_avg, temp_isothermality,...</td>\n",
       "      <td>-1.036112</td>\n",
       "      <td>0.422984</td>\n",
       "      <td>0.20</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-0.979124</td>\n",
       "      <td>0.454820</td>\n",
       "      <td>0.20</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp_per_capita, temp_avg, temp_isothermality,...</td>\n",
       "      <td>-1.024542</td>\n",
       "      <td>0.429264</td>\n",
       "      <td>0.20</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model num_features                                           Features  \\\n",
       "0    XGB           63                                   All w/ climzones   \n",
       "1    XGB            5  [gdp, gdp_per_capita, gpw_population, precip, ...   \n",
       "2    XGB           63                                   All w/ climzones   \n",
       "3    XGB            5  [gdp, gpw_population, temp_isothermality, prec...   \n",
       "4    XGB           63                                   All w/ climzones   \n",
       "5    XGB            5  [gdp, gpw_population, temp_seasonality, pixel_...   \n",
       "6    XGB           63                                   All w/ climzones   \n",
       "7    XGB            5  [gdp, temp_isothermality, precip, pixel_id_flo...   \n",
       "8    XGB           63                                   All w/ climzones   \n",
       "9    XGB            5  [gpw_population, temp_seasonality, precip, pix...   \n",
       "10   XGB           63                                   All w/ climzones   \n",
       "11   XGB            5  [gdp_per_capita, gpw_population, temp_isotherm...   \n",
       "12   XGB           63                                   All w/ climzones   \n",
       "13   XGB            5  [gdp, temp_isothermality, precip, pixel_id_flo...   \n",
       "14   XGB           63                                   All w/ climzones   \n",
       "15   XGB            5  [gdp, temp_isothermality, precip, pixel_id_flo...   \n",
       "16   XGB           63                                   All w/ climzones   \n",
       "17   XGB            5  [gdp, temp_isothermality, precip, pixel_id_flo...   \n",
       "18   XGB           63                                   All w/ climzones   \n",
       "19   XGB            5  [temp_avg, temp_seasonality, precip, pixel_id_...   \n",
       "20   XGB           63                                   All w/ climzones   \n",
       "21   XGB            5  [gdp, temp_isothermality, precip, pixel_id_flo...   \n",
       "22   XGB           63                                   All w/ climzones   \n",
       "23   XGB            5  [temp_avg, temp_isothermality, precip, pixel_i...   \n",
       "24   XGB           63                                   All w/ climzones   \n",
       "25   XGB            5  [gdp, gpw_population, temp_seasonality, pixel_...   \n",
       "26   XGB           63                                   All w/ climzones   \n",
       "27   XGB            5  [gdp_per_capita, temp_isothermality, precip, p...   \n",
       "28   XGB           63                                   All w/ climzones   \n",
       "29   XGB            5  [gdp_per_capita, temp_avg, temp_seasonality, p...   \n",
       "30   XGB           63                                   All w/ climzones   \n",
       "31   XGB            5  [gdp, temp_isothermality, precip, pixel_id_flo...   \n",
       "32   XGB           63                                   All w/ climzones   \n",
       "33   XGB            5  [gdp_per_capita, temp_isothermality, precip, p...   \n",
       "34   XGB           63                                   All w/ climzones   \n",
       "35   XGB            5  [temp_isothermality, temp_seasonality, precip,...   \n",
       "36   XGB           63                                   All w/ climzones   \n",
       "37   XGB            5  [gdp_per_capita, temp_avg, temp_isothermality,...   \n",
       "38   XGB           63                                   All w/ climzones   \n",
       "39   XGB            5  [gdp_per_capita, temp_avg, temp_isothermality,...   \n",
       "\n",
       "         MSE        R2  learning_rate n_estimators  \n",
       "0  -5.497892 -2.089663           0.05           40  \n",
       "1  -5.540515 -2.113769           0.05           40  \n",
       "2  -2.066128 -0.157652           0.05           55  \n",
       "3  -2.099935 -0.176934           0.05           55  \n",
       "4  -1.308465  0.269557           0.05           70  \n",
       "5  -1.348030  0.246828           0.05           70  \n",
       "6  -1.132156  0.369255           0.05           85  \n",
       "7  -1.201914  0.329596           0.05           85  \n",
       "8  -1.086096  0.395434           0.05          100  \n",
       "9  -1.122087  0.374878           0.05          100  \n",
       "10 -1.154087  0.356876           0.10           40  \n",
       "11 -1.198791  0.331388           0.10           40  \n",
       "12 -1.073663  0.402439           0.10           55  \n",
       "13 -1.133450  0.368402           0.10           55  \n",
       "14 -1.051028  0.415256           0.10           70  \n",
       "15 -1.111683  0.380958           0.10           70  \n",
       "16 -1.035525  0.423852           0.10           85  \n",
       "17 -1.093491  0.391188           0.10           85  \n",
       "18 -1.025111  0.429631           0.10          100  \n",
       "19 -1.096368  0.389523           0.10          100  \n",
       "20 -1.064797  0.407514           0.15           40  \n",
       "21 -1.116909  0.377690           0.15           40  \n",
       "22 -1.036606  0.423398           0.15           55  \n",
       "23 -1.115429  0.378726           0.15           55  \n",
       "24 -1.018475  0.433426           0.15           70  \n",
       "25 -1.032307  0.424519           0.15           70  \n",
       "26 -1.004901  0.440884           0.15           85  \n",
       "27 -1.067904  0.405698           0.15           85  \n",
       "28 -0.992543  0.447846           0.15          100  \n",
       "29 -1.049283  0.414577           0.15          100  \n",
       "30 -1.043318  0.419257           0.20           40  \n",
       "31 -1.099753  0.387689           0.20           40  \n",
       "32 -1.022760  0.430771           0.20           55  \n",
       "33 -1.083079  0.396946           0.20           55  \n",
       "34 -1.003162  0.441608           0.20           70  \n",
       "35 -1.085194  0.395606           0.20           70  \n",
       "36 -0.989310  0.449312           0.20           85  \n",
       "37 -1.036112  0.422984           0.20           85  \n",
       "38 -0.979124  0.454820           0.20          100  \n",
       "39 -1.024542  0.429264           0.20          100  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>num_features</th>\n",
       "      <th>Features</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-5.497892</td>\n",
       "      <td>-2.089663</td>\n",
       "      <td>0.05</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp, gdp_per_capita, gpw_population, precip, ...</td>\n",
       "      <td>-5.540515</td>\n",
       "      <td>-2.113769</td>\n",
       "      <td>0.05</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-2.066128</td>\n",
       "      <td>-0.157652</td>\n",
       "      <td>0.05</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp, gpw_population, temp_isothermality, prec...</td>\n",
       "      <td>-2.099935</td>\n",
       "      <td>-0.176934</td>\n",
       "      <td>0.05</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.308465</td>\n",
       "      <td>0.269557</td>\n",
       "      <td>0.05</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp, gpw_population, temp_seasonality, pixel_...</td>\n",
       "      <td>-1.348030</td>\n",
       "      <td>0.246828</td>\n",
       "      <td>0.05</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.132156</td>\n",
       "      <td>0.369255</td>\n",
       "      <td>0.05</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp, gpw_population, temp_isothermality, prec...</td>\n",
       "      <td>-1.182342</td>\n",
       "      <td>0.340756</td>\n",
       "      <td>0.05</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.086096</td>\n",
       "      <td>0.395434</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp, temp_isothermality, precip, pixel_id_flo...</td>\n",
       "      <td>-1.151912</td>\n",
       "      <td>0.357973</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.154087</td>\n",
       "      <td>0.356876</td>\n",
       "      <td>0.10</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp, temp_isothermality, precip, pixel_id_flo...</td>\n",
       "      <td>-1.222768</td>\n",
       "      <td>0.317771</td>\n",
       "      <td>0.10</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.073663</td>\n",
       "      <td>0.402439</td>\n",
       "      <td>0.10</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp_per_capita, gpw_population, temp_seasonal...</td>\n",
       "      <td>-1.104060</td>\n",
       "      <td>0.384653</td>\n",
       "      <td>0.10</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.051028</td>\n",
       "      <td>0.415256</td>\n",
       "      <td>0.10</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp_per_capita, temp_isothermality, precip, p...</td>\n",
       "      <td>-1.120287</td>\n",
       "      <td>0.375855</td>\n",
       "      <td>0.10</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.035525</td>\n",
       "      <td>0.423852</td>\n",
       "      <td>0.10</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp, temp_isothermality, precip, pixel_id_flo...</td>\n",
       "      <td>-1.093491</td>\n",
       "      <td>0.391188</td>\n",
       "      <td>0.10</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.025111</td>\n",
       "      <td>0.429631</td>\n",
       "      <td>0.10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[altitude, temp_seasonality, precip, pixel_id_...</td>\n",
       "      <td>-1.083712</td>\n",
       "      <td>0.396399</td>\n",
       "      <td>0.10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.064797</td>\n",
       "      <td>0.407514</td>\n",
       "      <td>0.15</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp_per_capita, temp_isothermality, precip, p...</td>\n",
       "      <td>-1.126827</td>\n",
       "      <td>0.372101</td>\n",
       "      <td>0.15</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.036606</td>\n",
       "      <td>0.423398</td>\n",
       "      <td>0.15</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[altitude, temp_seasonality, precip, pixel_id_...</td>\n",
       "      <td>-1.090063</td>\n",
       "      <td>0.393004</td>\n",
       "      <td>0.15</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.018475</td>\n",
       "      <td>0.433426</td>\n",
       "      <td>0.15</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp_per_capita, temp_seasonality, precip, pix...</td>\n",
       "      <td>-1.084610</td>\n",
       "      <td>0.395673</td>\n",
       "      <td>0.15</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.004901</td>\n",
       "      <td>0.440884</td>\n",
       "      <td>0.15</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[altitude, temp_seasonality, precip, pixel_id_...</td>\n",
       "      <td>-1.062633</td>\n",
       "      <td>0.408110</td>\n",
       "      <td>0.15</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-0.992543</td>\n",
       "      <td>0.447846</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp_per_capita, temp_isothermality, precip, p...</td>\n",
       "      <td>-1.056550</td>\n",
       "      <td>0.411927</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-0.983160</td>\n",
       "      <td>0.453049</td>\n",
       "      <td>0.15</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp, gdp_per_capita, temp_seasonality, pixel_...</td>\n",
       "      <td>-1.026230</td>\n",
       "      <td>0.427456</td>\n",
       "      <td>0.15</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.013990</td>\n",
       "      <td>0.435636</td>\n",
       "      <td>0.20</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[temp_avg, temp_isothermality, precip, pixel_i...</td>\n",
       "      <td>-1.088551</td>\n",
       "      <td>0.394141</td>\n",
       "      <td>0.20</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-1.002904</td>\n",
       "      <td>0.441811</td>\n",
       "      <td>0.20</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp_per_capita, temp_avg, temp_isothermality,...</td>\n",
       "      <td>-1.054256</td>\n",
       "      <td>0.412816</td>\n",
       "      <td>0.20</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-0.995760</td>\n",
       "      <td>0.445801</td>\n",
       "      <td>0.20</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[temp_avg, temp_isothermality, precip, pixel_i...</td>\n",
       "      <td>-1.067546</td>\n",
       "      <td>0.405990</td>\n",
       "      <td>0.20</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-0.984816</td>\n",
       "      <td>0.451796</td>\n",
       "      <td>0.20</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp_per_capita, temp_isothermality, precip, p...</td>\n",
       "      <td>-1.051726</td>\n",
       "      <td>0.414660</td>\n",
       "      <td>0.20</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-0.979271</td>\n",
       "      <td>0.454717</td>\n",
       "      <td>0.20</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp_per_capita, temp_isothermality, precip, p...</td>\n",
       "      <td>-1.046748</td>\n",
       "      <td>0.417458</td>\n",
       "      <td>0.20</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-0.972406</td>\n",
       "      <td>0.458428</td>\n",
       "      <td>0.20</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp_per_capita, temp_avg, temp_isothermality,...</td>\n",
       "      <td>-1.019571</td>\n",
       "      <td>0.431869</td>\n",
       "      <td>0.20</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-0.969539</td>\n",
       "      <td>0.460006</td>\n",
       "      <td>0.20</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[temp_avg, temp_isothermality, precip, pixel_i...</td>\n",
       "      <td>-1.048142</td>\n",
       "      <td>0.416912</td>\n",
       "      <td>0.20</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-0.998225</td>\n",
       "      <td>0.444316</td>\n",
       "      <td>0.25</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[temp_avg, temp_isothermality, precip, pixel_i...</td>\n",
       "      <td>-1.079127</td>\n",
       "      <td>0.399325</td>\n",
       "      <td>0.25</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-0.992390</td>\n",
       "      <td>0.447765</td>\n",
       "      <td>0.25</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[temp_avg, temp_isothermality, precip, pixel_i...</td>\n",
       "      <td>-1.071299</td>\n",
       "      <td>0.403754</td>\n",
       "      <td>0.25</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-0.988336</td>\n",
       "      <td>0.449977</td>\n",
       "      <td>0.25</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp_per_capita, temp_isothermality, precip, p...</td>\n",
       "      <td>-1.046276</td>\n",
       "      <td>0.417885</td>\n",
       "      <td>0.25</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-0.979837</td>\n",
       "      <td>0.454658</td>\n",
       "      <td>0.25</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp_per_capita, temp_avg, temp_isothermality,...</td>\n",
       "      <td>-1.047873</td>\n",
       "      <td>0.417193</td>\n",
       "      <td>0.25</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-0.971211</td>\n",
       "      <td>0.459360</td>\n",
       "      <td>0.25</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp_per_capita, temp_avg, temp_seasonality, p...</td>\n",
       "      <td>-1.020393</td>\n",
       "      <td>0.430783</td>\n",
       "      <td>0.25</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-0.967980</td>\n",
       "      <td>0.461211</td>\n",
       "      <td>0.25</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp_per_capita, temp_isothermality, temp_seas...</td>\n",
       "      <td>-1.044533</td>\n",
       "      <td>0.417315</td>\n",
       "      <td>0.25</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>XGB</td>\n",
       "      <td>63</td>\n",
       "      <td>All w/ climzones</td>\n",
       "      <td>-0.967635</td>\n",
       "      <td>0.461411</td>\n",
       "      <td>0.25</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>XGB</td>\n",
       "      <td>5</td>\n",
       "      <td>[gdp_per_capita, temp_isothermality, temp_seas...</td>\n",
       "      <td>-1.036446</td>\n",
       "      <td>0.421872</td>\n",
       "      <td>0.25</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model num_features                                           Features  \\\n",
       "0    XGB           63                                   All w/ climzones   \n",
       "1    XGB            5  [gdp, gdp_per_capita, gpw_population, precip, ...   \n",
       "2    XGB           63                                   All w/ climzones   \n",
       "3    XGB            5  [gdp, gpw_population, temp_isothermality, prec...   \n",
       "4    XGB           63                                   All w/ climzones   \n",
       "5    XGB            5  [gdp, gpw_population, temp_seasonality, pixel_...   \n",
       "6    XGB           63                                   All w/ climzones   \n",
       "7    XGB            5  [gdp, gpw_population, temp_isothermality, prec...   \n",
       "8    XGB           63                                   All w/ climzones   \n",
       "9    XGB            5  [gdp, temp_isothermality, precip, pixel_id_flo...   \n",
       "10   XGB           63                                   All w/ climzones   \n",
       "11   XGB            5  [gdp, temp_isothermality, precip, pixel_id_flo...   \n",
       "12   XGB           63                                   All w/ climzones   \n",
       "13   XGB            5  [gdp_per_capita, gpw_population, temp_seasonal...   \n",
       "14   XGB           63                                   All w/ climzones   \n",
       "15   XGB            5  [gdp_per_capita, temp_isothermality, precip, p...   \n",
       "16   XGB           63                                   All w/ climzones   \n",
       "17   XGB            5  [gdp, temp_isothermality, precip, pixel_id_flo...   \n",
       "18   XGB           63                                   All w/ climzones   \n",
       "19   XGB            5  [altitude, temp_seasonality, precip, pixel_id_...   \n",
       "20   XGB           63                                   All w/ climzones   \n",
       "21   XGB            5  [gdp_per_capita, temp_isothermality, precip, p...   \n",
       "22   XGB           63                                   All w/ climzones   \n",
       "23   XGB            5  [altitude, temp_seasonality, precip, pixel_id_...   \n",
       "24   XGB           63                                   All w/ climzones   \n",
       "25   XGB            5  [gdp_per_capita, temp_seasonality, precip, pix...   \n",
       "26   XGB           63                                   All w/ climzones   \n",
       "27   XGB            5  [altitude, temp_seasonality, precip, pixel_id_...   \n",
       "28   XGB           63                                   All w/ climzones   \n",
       "29   XGB            5  [gdp_per_capita, temp_isothermality, precip, p...   \n",
       "..   ...          ...                                                ...   \n",
       "66   XGB           63                                   All w/ climzones   \n",
       "67   XGB            5  [gdp, gdp_per_capita, temp_seasonality, pixel_...   \n",
       "68   XGB           63                                   All w/ climzones   \n",
       "69   XGB            5  [temp_avg, temp_isothermality, precip, pixel_i...   \n",
       "70   XGB           63                                   All w/ climzones   \n",
       "71   XGB            5  [gdp_per_capita, temp_avg, temp_isothermality,...   \n",
       "72   XGB           63                                   All w/ climzones   \n",
       "73   XGB            5  [temp_avg, temp_isothermality, precip, pixel_i...   \n",
       "74   XGB           63                                   All w/ climzones   \n",
       "75   XGB            5  [gdp_per_capita, temp_isothermality, precip, p...   \n",
       "76   XGB           63                                   All w/ climzones   \n",
       "77   XGB            5  [gdp_per_capita, temp_isothermality, precip, p...   \n",
       "78   XGB           63                                   All w/ climzones   \n",
       "79   XGB            5  [gdp_per_capita, temp_avg, temp_isothermality,...   \n",
       "80   XGB           63                                   All w/ climzones   \n",
       "81   XGB            5  [temp_avg, temp_isothermality, precip, pixel_i...   \n",
       "82   XGB           63                                   All w/ climzones   \n",
       "83   XGB            5  [temp_avg, temp_isothermality, precip, pixel_i...   \n",
       "84   XGB           63                                   All w/ climzones   \n",
       "85   XGB            5  [temp_avg, temp_isothermality, precip, pixel_i...   \n",
       "86   XGB           63                                   All w/ climzones   \n",
       "87   XGB            5  [gdp_per_capita, temp_isothermality, precip, p...   \n",
       "88   XGB           63                                   All w/ climzones   \n",
       "89   XGB            5  [gdp_per_capita, temp_avg, temp_isothermality,...   \n",
       "90   XGB           63                                   All w/ climzones   \n",
       "91   XGB            5  [gdp_per_capita, temp_avg, temp_seasonality, p...   \n",
       "92   XGB           63                                   All w/ climzones   \n",
       "93   XGB            5  [gdp_per_capita, temp_isothermality, temp_seas...   \n",
       "94   XGB           63                                   All w/ climzones   \n",
       "95   XGB            5  [gdp_per_capita, temp_isothermality, temp_seas...   \n",
       "\n",
       "         MSE        R2  learning_rate n_estimators  \n",
       "0  -5.497892 -2.089663           0.05           40  \n",
       "1  -5.540515 -2.113769           0.05           40  \n",
       "2  -2.066128 -0.157652           0.05           55  \n",
       "3  -2.099935 -0.176934           0.05           55  \n",
       "4  -1.308465  0.269557           0.05           70  \n",
       "5  -1.348030  0.246828           0.05           70  \n",
       "6  -1.132156  0.369255           0.05           85  \n",
       "7  -1.182342  0.340756           0.05           85  \n",
       "8  -1.086096  0.395434           0.05          100  \n",
       "9  -1.151912  0.357973           0.05          100  \n",
       "10 -1.154087  0.356876           0.10           40  \n",
       "11 -1.222768  0.317771           0.10           40  \n",
       "12 -1.073663  0.402439           0.10           55  \n",
       "13 -1.104060  0.384653           0.10           55  \n",
       "14 -1.051028  0.415256           0.10           70  \n",
       "15 -1.120287  0.375855           0.10           70  \n",
       "16 -1.035525  0.423852           0.10           85  \n",
       "17 -1.093491  0.391188           0.10           85  \n",
       "18 -1.025111  0.429631           0.10          100  \n",
       "19 -1.083712  0.396399           0.10          100  \n",
       "20 -1.064797  0.407514           0.15           40  \n",
       "21 -1.126827  0.372101           0.15           40  \n",
       "22 -1.036606  0.423398           0.15           55  \n",
       "23 -1.090063  0.393004           0.15           55  \n",
       "24 -1.018475  0.433426           0.15           70  \n",
       "25 -1.084610  0.395673           0.15           70  \n",
       "26 -1.004901  0.440884           0.15           85  \n",
       "27 -1.062633  0.408110           0.15           85  \n",
       "28 -0.992543  0.447846           0.15          100  \n",
       "29 -1.056550  0.411927           0.15          100  \n",
       "..       ...       ...            ...          ...  \n",
       "66 -0.983160  0.453049           0.15          120  \n",
       "67 -1.026230  0.427456           0.15          120  \n",
       "68 -1.013990  0.435636           0.20           60  \n",
       "69 -1.088551  0.394141           0.20           60  \n",
       "70 -1.002904  0.441811           0.20           71  \n",
       "71 -1.054256  0.412816           0.20           71  \n",
       "72 -0.995760  0.445801           0.20           80  \n",
       "73 -1.067546  0.405990           0.20           80  \n",
       "74 -0.984816  0.451796           0.20           90  \n",
       "75 -1.051726  0.414660           0.20           90  \n",
       "76 -0.979271  0.454717           0.20          101  \n",
       "77 -1.046748  0.417458           0.20          101  \n",
       "78 -0.972406  0.458428           0.20          110  \n",
       "79 -1.019571  0.431869           0.20          110  \n",
       "80 -0.969539  0.460006           0.20          120  \n",
       "81 -1.048142  0.416912           0.20          120  \n",
       "82 -0.998225  0.444316           0.25           60  \n",
       "83 -1.079127  0.399325           0.25           60  \n",
       "84 -0.992390  0.447765           0.25           71  \n",
       "85 -1.071299  0.403754           0.25           71  \n",
       "86 -0.988336  0.449977           0.25           80  \n",
       "87 -1.046276  0.417885           0.25           80  \n",
       "88 -0.979837  0.454658           0.25           90  \n",
       "89 -1.047873  0.417193           0.25           90  \n",
       "90 -0.971211  0.459360           0.25          101  \n",
       "91 -1.020393  0.430783           0.25          101  \n",
       "92 -0.967980  0.461211           0.25          110  \n",
       "93 -1.044533  0.417315           0.25          110  \n",
       "94 -0.967635  0.461411           0.25          120  \n",
       "95 -1.036446  0.421872           0.25          120  \n",
       "\n",
       "[96 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_tuning2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_regressor = xgb.XGBRegressor()\n",
    "\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [.03, .07, .2], #so called `eta` value\n",
    "              'max_depth': [3, 5, 7],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.5,0.75,1],\n",
    "              'colsample_bytree': [0.5,0.75,1],\n",
    "              'n_estimators': [300,500,600]}\n",
    "\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb_regressor,\n",
    "                        parameters,\n",
    "                        cv = 2,\n",
    "                        n_jobs = 5,\n",
    "                        verbose=True)\n",
    "\n",
    "x = df.drop(['calories_per_ha'], axis=1)\n",
    "y = df['calories_per_ha']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y)\n",
    "xgb_grid.fit(X_train,\n",
    "         y_train)\n",
    "\n",
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results from cell above\n",
    "# Fitting 2 folds for each of 243 candidates, totalling 486 fits | elapsed: 16.0min finished\n",
    "best_R2 = 0.44336470168217684\n",
    "best_parameters = {'colsample_bytree': 0.75, 'learning_rate': 0.03, 'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 600, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.75}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.05 -- n_estimators = 40  -- \n",
      "    with all features...\n",
      "    R2_score : -2.089662843804917\n",
      "    MSE_score : -5.497891785362941\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : -2.1137687302130006\n",
      "    MSE_score : -5.540515274035159\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.05 -- n_estimators = 55  -- \n",
      "    with all features...\n",
      "    R2_score : -0.15765197131771708\n",
      "    MSE_score : -2.066127521164086\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : -0.17693431412043975\n",
      "    MSE_score : -2.0999350521574263\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.05 -- n_estimators = 70  -- \n",
      "    with all features...\n",
      "    R2_score : 0.2695568240841067\n",
      "    MSE_score : -1.3084654633817094\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.24682794796441362\n",
      "    MSE_score : -1.3480304976032282\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.05 -- n_estimators = 85  -- \n",
      "    with all features...\n",
      "    R2_score : 0.3692546887871212\n",
      "    MSE_score : -1.1321555945526434\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.32959599838890946\n",
      "    MSE_score : -1.2019140554971757\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.05 -- n_estimators = 100  -- \n",
      "    with all features...\n",
      "    R2_score : 0.39543406979017115\n",
      "    MSE_score : -1.0860957148106405\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.37487769971103746\n",
      "    MSE_score : -1.1220867679144997\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.1 -- n_estimators = 40  -- \n",
      "    with all features...\n",
      "    R2_score : 0.3568755734299513\n",
      "    MSE_score : -1.1540865016318491\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.33138836313537007\n",
      "    MSE_score : -1.1987909292009942\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.1 -- n_estimators = 55  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4024393077849405\n",
      "    MSE_score : -1.0736631189783818\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.3684020838923766\n",
      "    MSE_score : -1.1334497808516975\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.1 -- n_estimators = 70  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4152563784378427\n",
      "    MSE_score : -1.0510276712586915\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.3809575192703091\n",
      "    MSE_score : -1.1116828912475083\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.1 -- n_estimators = 85  -- \n",
      "    with all features...\n",
      "    R2_score : 0.42385247395888526\n",
      "    MSE_score : -1.0355248404675959\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.39118833435287004\n",
      "    MSE_score : -1.0934908153792842\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.1 -- n_estimators = 100  -- \n",
      "    with all features...\n",
      "    R2_score : 0.42963066019295554\n",
      "    MSE_score : -1.025111013372745\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.38952293352533374\n",
      "    MSE_score : -1.0963676539068627\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.15 -- n_estimators = 40  -- \n",
      "    with all features...\n",
      "    R2_score : 0.40751395216220654\n",
      "    MSE_score : -1.0647974257943162\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.37768991407704416\n",
      "    MSE_score : -1.1169088395379188\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.15 -- n_estimators = 55  -- \n",
      "    with all features...\n",
      "    R2_score : 0.42339808903564274\n",
      "    MSE_score : -1.03660639731994\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.37872615797946263\n",
      "    MSE_score : -1.115428914797226\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.15 -- n_estimators = 70  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4334264115038796\n",
      "    MSE_score : -1.018474930134619\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.4245190117952139\n",
      "    MSE_score : -1.0323065439422854\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.15 -- n_estimators = 85  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4408841688778784\n",
      "    MSE_score : -1.0049009332531038\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.40569810371729104\n",
      "    MSE_score : -1.0679044582509585\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.15 -- n_estimators = 100  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4478456729018415\n",
      "    MSE_score : -0.992542895942463\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.41457665127855803\n",
      "    MSE_score : -1.0492828135790908\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.2 -- n_estimators = 40  -- \n",
      "    with all features...\n",
      "    R2_score : 0.41925708016665186\n",
      "    MSE_score : -1.0433175953261913\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.38768868857084987\n",
      "    MSE_score : -1.0997533705864166\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.2 -- n_estimators = 55  -- \n",
      "    with all features...\n",
      "    R2_score : 0.43077126464876503\n",
      "    MSE_score : -1.0227604605363927\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.3969462517476524\n",
      "    MSE_score : -1.0830791634372126\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.2 -- n_estimators = 70  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4416081987218883\n",
      "    MSE_score : -1.003162141125355\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.3956064139018287\n",
      "    MSE_score : -1.0851938247561208\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.2 -- n_estimators = 85  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4493115637278061\n",
      "    MSE_score : -0.9893101680908662\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.4229844017831684\n",
      "    MSE_score : -1.0361121567436804\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.2 -- n_estimators = 100  -- \n",
      "    with all features...\n",
      "    R2_score : 0.4548195624605576\n",
      "    MSE_score : -0.9791243117655654\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R2_score : 0.4292635093682267\n",
      "    MSE_score : -1.024542445992736\n",
      "    ... done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Â Testing XGBoost with params (RESULTS BELOW WITH CLIMZONES)\n",
    "\n",
    "model = 'XGB'\n",
    "## Step 2: tuning tree-based parameters\n",
    "\n",
    "learning_rate = 0.2:\n",
    "n_estimators = 100:\n",
    "    \n",
    "    for min_samples_split in [500 ... ### ~0.5-1% of total values\n",
    "           for max_depth in range (5,9):                   \n",
    "                              \n",
    "                              \n",
    "        print('Running XGBoost with params:')\n",
    "        print(' -- Learning Rate = ' + str(learning_rate) +' -- n_estimators = ' + str(n_estimators) + '  -- ')\n",
    "        \n",
    "        regression = xgb.XGBRegressor(learning_rate = learning_rate,n_estimators = n_estimators)\n",
    "\n",
    "\n",
    "\n",
    "        # Doing it will all features\n",
    "        print('    with all features...')\n",
    "        num_features = len(df.columns)-2\n",
    "        Features = 'All w/ climzones'\n",
    "        \n",
    "        scores = do_regression(regression,df)\n",
    "\n",
    "        print('    R2_score : '+str(scores[0]))\n",
    "        print('    MSE_score : '+str(scores[1]))\n",
    "        \n",
    "        R2_score = scores[0]\n",
    "        MSE_score = scores[1]\n",
    "        \n",
    "        xgb_tuning = xgb_tuning.append({'Model': model,\n",
    "                                        'num_features':len(df.columns)-1,'Features':'All w/ climzones',\n",
    "                                        'learning_rate':learning_rate,'n_estimators':n_estimators,\n",
    "                                        'R2':R2_score,'MSE':MSE_score},ignore_index=True)\n",
    "\n",
    "        print('    ... done')\n",
    "\n",
    "        # Iterate over â  numbers of features\n",
    "        for num_features in range (5,6):\n",
    "\n",
    "            print('    with '+str(num_features)+ ' features ...')\n",
    "\n",
    "            ## RFE - Features selection\n",
    "            selector = RFE(regression, num_features, step=1)\n",
    "\n",
    "            x = df.drop(['calories_per_ha'], axis=1) ## TODO climate_zones encode One Hot Encoder\n",
    "            y = df['calories_per_ha']\n",
    "            X, X_test, Y, Y_test = train_test_split(x, y)\n",
    "\n",
    "            X_RFE = selector.fit_transform(X,Y)\n",
    "\n",
    "            features_selected = [X.columns[feature_pos] for feature_pos in selector.get_support(indices=True)]\n",
    "            features_selected.append('calories_per_ha')\n",
    "            scores = do_regression(regression,df[features_selected])\n",
    "            print('    R2_score : '+str(scores[0]))\n",
    "            print('    MSE_score : '+str(scores[1]))\n",
    "            \n",
    "            R2_score = scores[0]\n",
    "            MSE_score = scores[1]\n",
    "            xgb_tuning = xgb_tuning.append({'Model': model,\n",
    "                                        'num_features':num_features,'Features':features_selected,\n",
    "                                        'learning_rate':learning_rate,'n_estimators':n_estimators,\n",
    "                                        'R2':R2_score,'MSE':MSE_score},ignore_index=True)\n",
    "    \n",
    "    \n",
    "            print('    ... done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.05      -- n_estimators = 40  -- \n",
      "    with all features...\n",
      "R2_score : -2.0532010678759955\n",
      "MSE_score : -5.538779158384349\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score : -2.062889586949815\n",
      "MSE_score : -5.557887544404986\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.05      -- n_estimators = 55  -- \n",
      "    with all features...\n",
      "R2_score : -0.16055914011633768\n",
      "MSE_score : -2.11514207387677\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score : -0.17510470189948146\n",
      "MSE_score : -2.142804533705525\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.05      -- n_estimators = 70  -- \n",
      "    with all features...\n",
      "R2_score : 0.2568721021318591\n",
      "MSE_score : -1.3613612548597505\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score : 0.24465703273188613\n",
      "MSE_score : -1.3846076017640911\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.05      -- n_estimators = 85  -- \n",
      "    with all features...\n",
      "R2_score : 0.3551451106829767\n",
      "MSE_score : -1.1840800173783423\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score : 0.340300758444985\n",
      "MSE_score : -1.2126132646480254\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.05      -- n_estimators = 100  -- \n",
      "    with all features...\n",
      "R2_score : 0.3828339739518645\n",
      "MSE_score : -1.1344433797026887\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score : 0.38318223194270556\n",
      "MSE_score : -1.1346428159359627\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.1      -- n_estimators = 40  -- \n",
      "    with all features...\n",
      "R2_score : 0.3463516680733554\n",
      "MSE_score : -1.1994597007191075\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score : 0.3453004373734923\n",
      "MSE_score : -1.202797215153806\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.1      -- n_estimators = 55  -- \n",
      "    with all features...\n",
      "R2_score : 0.39532669392455183\n",
      "MSE_score : -1.1114288570205484\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score : 0.3918343490612521\n",
      "MSE_score : -1.118887024273955\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.1      -- n_estimators = 70  -- \n",
      "    with all features...\n",
      "R2_score : 0.41024265446379743\n",
      "MSE_score : -1.0842512002993492\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score : 0.4057785941786925\n",
      "MSE_score : -1.0932343404332419\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.1      -- n_estimators = 85  -- \n",
      "    with all features...\n",
      "R2_score : 0.4204730811674449\n",
      "MSE_score : -1.0654301705780096\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score : 0.38388666942146155\n",
      "MSE_score : -1.1334035499676571\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.1      -- n_estimators = 100  -- \n",
      "    with all features...\n",
      "R2_score : 0.4265861120262967\n",
      "MSE_score : -1.0538964616918975\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score : 0.38054955269149404\n",
      "MSE_score : -1.1383899994725417\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.15      -- n_estimators = 40  -- \n",
      "    with all features...\n",
      "R2_score : 0.39846623194483266\n",
      "MSE_score : -1.1061102390943447\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score : 0.3854607453131912\n",
      "MSE_score : -1.1310923408639488\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.15      -- n_estimators = 55  -- \n",
      "    with all features...\n",
      "R2_score : 0.4154575483035595\n",
      "MSE_score : -1.07463043110042\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score : 0.41310179920609924\n",
      "MSE_score : -1.0800546155691264\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.15      -- n_estimators = 70  -- \n",
      "    with all features...\n",
      "R2_score : 0.424505715740767\n",
      "MSE_score : -1.0577984761219212\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score : 0.4017216180416604\n",
      "MSE_score : -1.1004231222624874\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.15      -- n_estimators = 85  -- \n",
      "    with all features...\n",
      "R2_score : 0.4321958678789656\n",
      "MSE_score : -1.0432812519850299\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score : 0.38575156556293444\n",
      "MSE_score : -1.1281003735463613\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.15      -- n_estimators = 100  -- \n",
      "    with all features...\n",
      "R2_score : 0.44000221969744546\n",
      "MSE_score : -1.0289767715393634\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score : 0.40599996233563795\n",
      "MSE_score : -1.0923351319583383\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.2      -- n_estimators = 40  -- \n",
      "    with all features...\n",
      "R2_score : 0.4148022864868933\n",
      "MSE_score : -1.0752565464183126\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score : 0.4203652862447863\n",
      "MSE_score : -1.0664630656924234\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.2      -- n_estimators = 55  -- \n",
      "    with all features...\n",
      "R2_score : 0.4268735708040213\n",
      "MSE_score : -1.0528041674047812\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score : 0.38082059970216237\n",
      "MSE_score : -1.1369797256065186\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.2      -- n_estimators = 70  -- \n",
      "    with all features...\n",
      "R2_score : 0.43946401597495266\n",
      "MSE_score : -1.0291915563456207\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score : 0.39950378901551514\n",
      "MSE_score : -1.103668666475499\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.2      -- n_estimators = 85  -- \n",
      "    with all features...\n",
      "R2_score : 0.44519683045001096\n",
      "MSE_score : -1.018385333734493\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score : 0.3972179349533541\n",
      "MSE_score : -1.1065808700047857\n",
      "    ... done \n",
      "\n",
      "Running XGBoost with params:\n",
      " -- Learning Rate = 0.2      -- n_estimators = 100  -- \n",
      "    with all features...\n",
      "R2_score : 0.4517768133687852\n",
      "MSE_score : -1.0055883137860309\n",
      "    ... done\n",
      "    with 5 features ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteweil1/anaconda/envs/spatialenv/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score : 0.4084606552649526\n",
      "MSE_score : -1.0864325330303806\n",
      "    ... done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Â Testing XGBoost with params -- RESULTS BELOW W/O CLIMATE ZONES\n",
    "\n",
    "model = 'XGB'\n",
    "## First choose: learning_rate, n_estimators\n",
    "for learning_rate in [0.05, 0.1, 0.15, 0.2]:\n",
    "    for n_estimators in [40,55,70,85,100]:\n",
    "        print('Running XGBoost with params:')\n",
    "        print(' -- Learning Rate = ' + str(learning_rate) +' -- n_estimators = ' + str(n_estimators) + '  -- ')\n",
    "        \n",
    "        regression = xgb.XGBRegressor(learning_rate = learning_rate,n_estimators = n_estimators)\n",
    "\n",
    "\n",
    "\n",
    "        # Doing it will all features\n",
    "        print('    with all features...')\n",
    "        num_features = len(df.columns)-2\n",
    "        Features = 'All EXCEPT climzones'\n",
    "        \n",
    "        scores = do_regression(regression,df.drop(['climate_zones'], axis=1))\n",
    "\n",
    "        print('    R2_score : '+str(scores[0]))\n",
    "        print('    MSE_score : '+str(scores[1]))\n",
    "        \n",
    "        R2_score = scores[0]\n",
    "        MSE_score = scores[1]\n",
    "        \n",
    "        xgb_tuning = xgb_tuning.append({'Model': model,\n",
    "                                        'num_features':num_features,'Features':features_selected,\n",
    "                                        'learning_rate':learning_rate,'n_estimators':n_estimators,\n",
    "                                        'R2':R2_score,'MSE':MSE_score},ignore_index=True)\n",
    "\n",
    "        print('    ... done')\n",
    "\n",
    "        # Iterate over â  numbers of features\n",
    "        for num_features in range (5,6):\n",
    "\n",
    "            print('    with '+str(num_features)+ ' features ...')\n",
    "\n",
    "            ## RFE - Features selection\n",
    "            selector = RFE(regression, num_features, step=1)\n",
    "\n",
    "            x = df.drop(['calories_per_ha','climate_zones'], axis=1) ## TODO climate_zones encode One Hot Encoder\n",
    "            y = df['calories_per_ha']\n",
    "            X, X_test, Y, Y_test = train_test_split(x, y)\n",
    "\n",
    "            X_RFE = selector.fit_transform(X,Y)\n",
    "\n",
    "            features_selected = [X.columns[feature_pos] for feature_pos in selector.get_support(indices=True)]\n",
    "            features_selected.append('calories_per_ha')\n",
    "            scores = do_regression(regression,df[features_selected])\n",
    "            print('    R2_score : '+str(scores[0]))\n",
    "            print('    MSE_score : '+str(scores[1]))\n",
    "    \n",
    "    \n",
    "            print('    ... done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(max_depth=3, learning_rate=0.1, n_estimators=100, silent=True, objective='reg:linear', booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First choose: learning_rate, n_estimators\n",
    "for learning_rate in [0.05, 0.1, 0.15, 0.2]:\n",
    "    for n_estimators in [40,55,70,85,100]:\n",
    "        print(' -- Learning Rate = ' + str(learning_rate) + '      -- n_estimators = ' + str(n_estimators) + '  -- ')\n",
    "        \n",
    "        regression = xgb.XGBRegressor(learning_rate = learning_rate,n_estimators = n_estimators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbreg = xgb.XGBRegressor()\n",
    "#n_estimators=500, learning_rate=00.08, gamma=0, subsample=0.65\n",
    "#                           colsample_bytree=0.7 # This results in an error\n",
    "#                          , max_depth=8)\n",
    "\n",
    "compare_predictions(xgbreg,df,show_df=True,show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbreg = xgb.XGBRegressor(objective = \"reg:logistic\")\n",
    "compare_predictions(xgbreg,datalice,show_df=True,show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing xgb.XGBRegressor\n",
    "\n",
    "datalice = pd.DataFrame (data={'calories_per_ha':[0,2,2,0,9,1,0,2,2,0,9,1,0,2,2,0,9,1,0,2,2,0,9,1],\n",
    "                               'predictor1':[0,3,3,1,10,10,0,3,3,1,10,10,0,3,3,1,10,10,0,3,3,1,10,10],\n",
    "                               'predictor2':[1,2,1,0,9,1,0,3,3,1,10,10,0,3,3,1,10,10,0,3,3,1,10,19],\n",
    "                               'predictor3':[11,21,20,9,91,10,11,21,20,9,91,10,11,21,20,9,91,10,11,21,20,9,91,10],\n",
    "                               'climate_zones':[11,21,20,9,91,10,11,21,20,9,91,10,11,21,20,9,91,10,11,21,20,9,91,10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalice.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOW LET'S TRY REGRESSIONS!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRY: linear, poly2, poly3, poly2+interactÂ°, poly3+interactÂ°, Ridge (â  params), Lasso (â  params), Tree-based approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without climate_zone dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg(dfBin) #old calories_per_cell with feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg(dfLog) #old calories_per_cell with feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg(dfLogBin) #old calories_per_cell with feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linreg(dfLog)\n",
    "type(df.iloc[2]['calories_per_ha'].astype(str))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With climate_zone dummies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg(dfLog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â (Looking at predicted values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dfLog\n",
    "\n",
    "x = dataframe.drop(['calories_per_ha'], axis=1)\n",
    "y = dataframe['calories_per_ha']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "y_predicted = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = pd.DataFrame()\n",
    "compare['y_test'] = y_test\n",
    "compare['predicted'] = y_predicted \n",
    "\n",
    "#Bunch of negative values\n",
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = compare.plot.scatter(x='y_test',y='predicted',s=0.5)\n",
    "ax.plot(ax.get_xlim(), ax.get_xlim(), ls=\"--\", c=\".3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5a' Reproduce Justin's Full reg\n",
    "*  d$precip_2 <- d$precip ^ 2\n",
    "            d$precip_3 <- d$precip ^ 3\n",
    "            d$temperature_2 <- d$temperature ^ 2\n",
    "            d$temperature_3 <- d$temperature ^ 3\n",
    "            d$minutes_to_market_2 <- d$minutes_to_market ^ 2\n",
    "            d$minutes_to_market_3 <- d$minutes_to_market ^ 3\n",
    "            d$gdp_gecon_2 <- d$gdp_gecon ^ 2\n",
    "            d$gdp_gecon_3 <- d$gdp_gecon ^ 3\n",
    "            d$altitude_2 <- d$altitude ^ 2\n",
    "            d$altitude_3 <- d$altitude ^ 3\n",
    "            d$slope_2 <- d$slope ^ 2\n",
    "            d$slope_3 <- d$slope ^ 3\n",
    "            d$crop_suitability_2 <- d$crop_suitability ^ 2\n",
    "            d$crop_suitability_3 <- d$crop_suitability ^ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFull = pd.DataFrame.copy(dfLog)\n",
    "\n",
    "#for var in ['precip','temperature','minutes_to_market','gdp_gecon','altitude','slope']:#,'crop_suitability']:\n",
    "for var in ['bio12','bio1','minutes_to_market_5m','gdp_per_capita_2000_5m','altitude','slope']:#,'crop_suitability']:\n",
    "    for i in range(2,4):\n",
    "        dfFull[var+str(i)] = dfFull[var].pow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for var in ['precip','temperature','minutes_to_market','gdp_gecon','altitude','slope']:#,'crop_suitability']:\n",
    "for var in ['bio12','bio1','minutes_to_market_5m','gdp_per_capita_2000_5m','altitude','slope']:#,'crop_suitability']:\n",
    "    for i in range(2,4):\n",
    "        dfFull[var+str(i)] = dfFull[var].pow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFull.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg(dfFull[['calories_per_ha', 'bio12', 'bio1', 'slope', 'altitude',\n",
    "       'workability_index', 'toxicity_index', 'rooting_conditions_index',\n",
    "       'oxygen_availability_index', 'nutrient_retention_index',\n",
    "       'nutrient_availability_index', 'excess_salts_index', 'gdp_2000',\n",
    "       'gdp_per_capita_2000_5m', 'minutes_to_market_5m','has_ag',\n",
    "       'bio13', 'bio122', 'bio123', 'minutes_to_market_5m2',\n",
    "       'minutes_to_market_5m3', 'gdp_per_capita_2000_5m2',\n",
    "       'gdp_per_capita_2000_5m3', 'altitude2', 'altitude3', 'slope2',\n",
    "       'slope3']]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg(dfFull) # Without climate zones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5b Models: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_reg(dataframe):\n",
    "    ##Must make dummies for categorical variable climate_zone\n",
    "    #dataframe = pd.get_dummies(dataframe, columns=['climate_zone'])\n",
    "    #Or just drop column if don't want dummies: (put following line under referecning of x)\n",
    "    #x = x.drop(['climate_zone'], axis=1)\n",
    "\n",
    "    x = dataframe.drop(['calories_per_ha'], axis=1)\n",
    "    y = dataframe['calories_per_ha']\n",
    "    \n",
    "\n",
    "    ### XGBoost Regressor\n",
    "    xgbreg = xgb.XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n",
    "                           colsample_bytree=1, max_depth=7)\n",
    "\n",
    "    ### Cross validation R2 score\n",
    "\n",
    "    cv_scores = cross_val_score(xgbreg, x, y, cv=10)\n",
    "\n",
    "    print('Mean R2 score: ', np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Without climate zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_reg(dfLog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_reg(dfFull)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With climate zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_reg(dfLog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dfLog\n",
    "\n",
    "x = dataframe.drop(['calories_per_ha'], axis=1)\n",
    "y = dataframe['calories_per_ha']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "xgbreg = xgb.XGBRegressor(n_estimators=200, learning_rate=0.08, gamma=1, subsample=0.75,\n",
    "                           colsample_bytree=1, max_depth=7)\n",
    "\n",
    "xg =  xgbreg.fit(X_train, y_train)\n",
    "y_predicted = xg.predict(X_test)\n",
    "\n",
    "compare = pd.DataFrame()\n",
    "compare['y_test'] = y_test\n",
    "compare['predicted'] = y_predicted \n",
    "\n",
    "#Bunch of negative values\n",
    "\n",
    "ax = compare.plot.scatter(x='y_test',y='predicted',s=0.5)\n",
    "ax.plot(ax.get_xlim(), ax.get_xlim(), ls=\"--\", c=\".3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5c Tobit (censored regression)\n",
    "\n",
    "## from https://github.com/jamesdj/tobit/blob/master/tobit.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from tobit import * --> Learn how to put the next cell tobit.py as a package??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import scipy.stats\n",
    "from scipy.special import log_ndtr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "def split_left_right_censored(x, y, cens):\n",
    "    counts = cens.value_counts()\n",
    "    if -1 not in counts and 1 not in counts:\n",
    "        warnings.warn(\"No censored observations; use regression methods for uncensored data\")\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for value in [-1, 0, 1]:\n",
    "        if value in counts:\n",
    "            split = cens == value\n",
    "            y_split = np.squeeze(y[split].values)\n",
    "            x_split = x[split].values\n",
    "\n",
    "        else:\n",
    "            y_split, x_split = None, None\n",
    "        xs.append(x_split)\n",
    "        ys.append(y_split)\n",
    "    return xs, ys\n",
    "\n",
    "\n",
    "def tobit_neg_log_likelihood(xs, ys, params):\n",
    "    x_left, x_mid, x_right = xs\n",
    "    y_left, y_mid, y_right = ys\n",
    "\n",
    "    b = params[:-1]\n",
    "    # s = math.exp(params[-1])\n",
    "    s = params[-1]\n",
    "\n",
    "    to_cat = []\n",
    "\n",
    "    cens = False\n",
    "    if y_left is not None:\n",
    "        cens = True\n",
    "        left = (y_left - np.dot(x_left, b))\n",
    "        to_cat.append(left)\n",
    "    if y_right is not None:\n",
    "        cens = True\n",
    "        right = (np.dot(x_right, b) - y_right)\n",
    "        to_cat.append(right)\n",
    "    if cens:\n",
    "        concat_stats = np.concatenate(to_cat, axis=0) / s\n",
    "        log_cum_norm = scipy.stats.norm.logcdf(concat_stats)  # log_ndtr(concat_stats)\n",
    "        cens_sum = log_cum_norm.sum()\n",
    "    else:\n",
    "        cens_sum = 0\n",
    "\n",
    "    if y_mid is not None:\n",
    "        mid_stats = (y_mid - np.dot(x_mid, b)) / s\n",
    "        mid = scipy.stats.norm.logpdf(mid_stats) - math.log(max(np.finfo('float').resolution, s))\n",
    "        mid_sum = mid.sum()\n",
    "    else:\n",
    "        mid_sum = 0\n",
    "\n",
    "    loglik = cens_sum + mid_sum\n",
    "\n",
    "    return - loglik\n",
    "\n",
    "\n",
    "def tobit_neg_log_likelihood_der(xs, ys, params):\n",
    "    x_left, x_mid, x_right = xs\n",
    "    y_left, y_mid, y_right = ys\n",
    "\n",
    "    b = params[:-1]\n",
    "    # s = math.exp(params[-1]) # in censReg, not using chain rule as below; they optimize in terms of log(s)\n",
    "    s = params[-1]\n",
    "\n",
    "    beta_jac = np.zeros(len(b))\n",
    "    sigma_jac = 0\n",
    "\n",
    "    if y_left is not None:\n",
    "        left_stats = (y_left - np.dot(x_left, b)) / s\n",
    "        l_pdf = scipy.stats.norm.logpdf(left_stats)\n",
    "        l_cdf = log_ndtr(left_stats)\n",
    "        left_frac = np.exp(l_pdf - l_cdf)\n",
    "        beta_left = np.dot(left_frac, x_left / s)\n",
    "        beta_jac -= beta_left\n",
    "\n",
    "        left_sigma = np.dot(left_frac, left_stats)\n",
    "        sigma_jac -= left_sigma\n",
    "\n",
    "    if y_right is not None:\n",
    "        right_stats = (np.dot(x_right, b) - y_right) / s\n",
    "        r_pdf = scipy.stats.norm.logpdf(right_stats)\n",
    "        r_cdf = log_ndtr(right_stats)\n",
    "        right_frac = np.exp(r_pdf - r_cdf)\n",
    "        beta_right = np.dot(right_frac, x_right / s)\n",
    "        beta_jac += beta_right\n",
    "\n",
    "        right_sigma = np.dot(right_frac, right_stats)\n",
    "        sigma_jac -= right_sigma\n",
    "\n",
    "    if y_mid is not None:\n",
    "        mid_stats = (y_mid - np.dot(x_mid, b)) / s\n",
    "        beta_mid = np.dot(mid_stats, x_mid / s)\n",
    "        beta_jac += beta_mid\n",
    "\n",
    "        mid_sigma = (np.square(mid_stats) - 1).sum()\n",
    "        sigma_jac += mid_sigma\n",
    "\n",
    "    combo_jac = np.append(beta_jac, sigma_jac / s)  # by chain rule, since the expression above is dloglik/dlogsigma\n",
    "\n",
    "    return -combo_jac\n",
    "\n",
    "\n",
    "class TobitModel:\n",
    "    def __init__(self, fit_intercept=True):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.ols_coef_ = None\n",
    "        self.ols_intercept = None\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.sigma_ = None\n",
    "\n",
    "    def fit(self, x, y, cens, verbose=False):\n",
    "        \"\"\"\n",
    "        Fit a maximum-likelihood Tobit regression\n",
    "        :param x: Pandas DataFrame (n_samples, n_features): Data\n",
    "        :param y: Pandas Series (n_samples,): Target\n",
    "        :param cens: Pandas Series (n_samples,): -1 indicates left-censored samples, 0 for uncensored, 1 for right-censored\n",
    "        :param verbose: boolean, show info from minimization\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x_copy = x.copy()\n",
    "        if self.fit_intercept:\n",
    "            x_copy.insert(0, 'intercept', 1.0)\n",
    "        else:\n",
    "            x_copy.scale(with_mean=True, with_std=False, copy=False)\n",
    "        init_reg = LinearRegression(fit_intercept=False).fit(x_copy, y)\n",
    "        b0 = init_reg.coef_\n",
    "        y_pred = init_reg.predict(x_copy)\n",
    "        resid = y - y_pred\n",
    "        resid_var = np.var(resid)\n",
    "        s0 = np.sqrt(resid_var)\n",
    "        params0 = np.append(b0, s0)\n",
    "        xs, ys = split_left_right_censored(x_copy, y, cens)\n",
    "\n",
    "        result = minimize(lambda params: tobit_neg_log_likelihood(xs, ys, params), params0, method='BFGS',\n",
    "                          jac=lambda params: tobit_neg_log_likelihood_der(xs, ys, params), options={'disp': verbose})\n",
    "        if verbose:\n",
    "            print(result)\n",
    "        self.ols_coef_ = b0[1:]\n",
    "        self.ols_intercept = b0[0]\n",
    "        if self.fit_intercept:\n",
    "            self.intercept_ = result.x[1]\n",
    "            self.coef_ = result.x[1:-1]\n",
    "        else:\n",
    "            self.coef_ = result.x[:-1]\n",
    "            self.intercept_ = 0\n",
    "        self.sigma_ = result.x[-1]\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.intercept_ + np.dot(x, self.coef_)\n",
    "\n",
    "    def score(self, x, y, scoring_function=mean_absolute_error):\n",
    "        y_pred = np.dot(x, self.coef_)\n",
    "        return scoring_function(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dfLog\n",
    "\n",
    "x = dataframe.drop(['calories_per_cell','climate_zone'], axis=1)\n",
    "y = dataframe['calories_per_cell']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "##Unsure about this 'cens' part\n",
    "cens = pd.Series(np.zeros((len(y_train),)))\n",
    "cens[left] = -1\n",
    "cens[right] = 1\n",
    "##See below\n",
    "\n",
    "tob = TobitModel().fit(X_train, y_train,cens)\n",
    "y_predicted = tob.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = pd.DataFrame()\n",
    "compare['y_test'] = y_test\n",
    "compare['predicted'] = y_predicted \n",
    "\n",
    "#Bunch of negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WTF? : below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cens = pd.Series(np.zeros((20,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cens[left] = -1\n",
    "cens[right] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spatialenv]",
   "language": "python",
   "name": "conda-env-spatialenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
