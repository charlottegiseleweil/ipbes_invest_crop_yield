{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    " \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "import xgboost as xgb\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import permutation_test_score\n",
    "\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "import hazelbean as hb\n",
    "\n",
    "#import seaborn as sns\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#pd.set_option('display.max_columns', 500) pd.set_option('display.max_rows', 500)\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(subset=True):\n",
    "    ''' subset takes values of : True/float/False\n",
    "            True : (sampling of 2% by default)\n",
    "            Float : Fraction to sample (e.g 0.10 for 10%)\n",
    "            False : returns df, X_validation, y_validation\n",
    "    '''\n",
    "    \n",
    "    #L.info('Loading data')\n",
    "    crop_types_df = pd.read_csv('../ipbes_invest_crop_yield_project/intermediate/aggregate_crops_by_type/aggregated_crop_data.csv')\n",
    "    df_land = pd.read_csv('../ipbes_invest_crop_yield_project/intermediate/create_baseline_regression_data/baseline_regression_data.csv')\n",
    "    #L.info('Data loaded')\n",
    "\n",
    "    df = crop_types_df.merge(df_land,how='outer',on='pixel_id')\n",
    "    #L.info('Data merged')\n",
    "\n",
    "    #Remove cal_per_ha per crop type for now\n",
    "    df = df.drop(labels=['c3_annual_calories_per_ha', 'c3_perennial_calories_per_ha',\n",
    "           'c4_annual_calories_per_ha', 'c4_perennial_calories_per_ha',\n",
    "           'nitrogen_fixer_calories_per_ha'], axis=1)\n",
    "\n",
    "    #Remove helper columns (not features)\n",
    "    df = df.drop(labels=['Unnamed: 0', 'country_ids',\n",
    "           'ha_per_cell_5m'], axis=1)\n",
    "\n",
    "    # Rename cols\n",
    "    df = df.rename(columns={'bio12': 'precip', 'bio1': 'temperature',\n",
    "                                'minutes_to_market_5m': 'min_to_market',\n",
    "                                'gdp_per_capita_2000_5m': 'gdp_per_capita',\n",
    "                                'gdp_2000': 'gdp'})\n",
    "    # Encode properly NaNs\n",
    "    df['slope'] = df['slope'].replace({0: np.nan})  # 143 NaN in 'slope' variable\n",
    "    for soil_var in ['workability_index', 'toxicity_index', 'rooting_conditions_index', 'oxygen_availability_index',\n",
    "                     'nutrient_retention_index', 'nutrient_availability_index', 'excess_salts_index']:\n",
    "        df[soil_var] = df[soil_var].replace({255: np.nan})\n",
    "        \n",
    "    # Drop NaN\n",
    "    df = df.dropna()\n",
    "    df = df[df['calories_per_ha'] != 0]    \n",
    "    \n",
    "    #Encode climate zones (as str)\n",
    "    climate_zones_map = {1:'Af',2:'Am',3:'Aw',\n",
    "                     5:'BWk',4:'BWh',7:'BSk',6:'BSh',\n",
    "                     14:'Cfa',15:'Cfb',16:'Cfc',8:'Csa',\n",
    "                     9:'Csb',10:'Csc',11:'Cwa',12:'Cwb',13:'Cwc',\n",
    "                     25:'Dfa',26:'Dfb',27:'Dfc',28:'Dfd',17:'Dsa',18:'Dsb',19:'Dsc',\n",
    "                     20:'Dsd',21:'Dwa',22:'Dwb',23:'Dwc',24:'Dwd',\n",
    "                     30:'EF',29:'ET'}\n",
    "    df['climate_zones'] = df['climate_zones'].map(climate_zones_map)\n",
    "    \n",
    "    #Â Encode climate zones as dummies\n",
    "    climate_dummies_df = pd.get_dummies(df['climate_zones'])\n",
    "    for col in climate_dummies_df.columns:\n",
    "        climate_dummies_df = climate_dummies_df.rename({col:str('climatezone_'+col)},axis=1)\n",
    "    \n",
    "    df = df.merge(climate_dummies_df, right_index=True,left_index=True)\n",
    "    df = df.drop('climate_zones',axis=1)\n",
    "    \n",
    "    # Lat/Lon\n",
    "    df['sin_lon'] = df['lon'].apply(lambda x:np.sin(np.radians(x)))\n",
    "    df = df.drop('lon',axis=1)\n",
    "    #df['sin_lat'] = df['lat'].apply(lambda x:np.sin(np.radians(x)))\n",
    "    \n",
    "    # Log some skewed variables\n",
    "    df['calories_per_ha'] = df['calories_per_ha'].apply(lambda x: np.log(x) if x != 0 else 0)\n",
    "\n",
    "    for col in ['gdp_per_capita','altitude', 'min_to_market', 'gpw_population']:\n",
    "        df[str('log_'+col)] = df[col].apply(lambda x: np.log(x) if x != 0 else 0)\n",
    "        df = df.drop(col,axis=1)\n",
    "        \n",
    "        \n",
    "    # Slope\n",
    "    df['slope'] = df['slope'].apply(lambda x:x-90)\n",
    "    \n",
    "    # Encode properly NaNs\n",
    "    df['slope'] = df['slope'].replace({0: np.nan})  # 143 NaN in 'slope' variable\n",
    "    for soil_var in ['workability_index', 'toxicity_index', 'rooting_conditions_index', 'oxygen_availability_index',\n",
    "                     'nutrient_retention_index', 'nutrient_availability_index', 'excess_salts_index']:\n",
    "        df[soil_var] = df[soil_var].replace({255: np.nan})\n",
    "        \n",
    "        \n",
    "    \n",
    "    # Cols to drop\n",
    "    for col in ['pixel_id_float', 'land_mask']:\n",
    "        df = df.drop(col,axis=1)\n",
    "        \n",
    "    if subset==True:\n",
    "        #subset = 0.02 if type(subset) is bool else subset\n",
    "        df = df.sample(frac=0.02, replace=False, weights=None, random_state=None, axis=0)\n",
    "\n",
    "    elif subset==False: #Save validation data\n",
    "        x = df.drop(['calories_per_ha'], axis=1)\n",
    "        y = df['calories_per_ha']\n",
    "        X, X_validation, Y, y_validation = train_test_split(x, y)\n",
    "        df = X.merge(pd.DataFrame(Y),how='outer',left_index=True,right_index=True)\n",
    "    \n",
    "    #Set index 'pixel_id'\n",
    "    df = df.set_index('pixel_id')\n",
    "    \n",
    "    y_val = pd.DataFrame(X_validation['pixel_id']).merge(pd.DataFrame(y_validation),how='outer',left_index=True,right_index=True)\n",
    "    y_validation = y_val.set_index('pixel_id')\n",
    "    X_validation = X_validation.set_index('pixel_id')\n",
    "\n",
    "    if subset==True:\n",
    "        return df\n",
    "    \n",
    "    elif subset==False:\n",
    "        return df, X_validation, y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, X_validation, y_validation = load_data(subset=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_without_climatezones = df.columns\n",
    "for col in df.columns:\n",
    "    if \"climatezone\" in col: \n",
    "        columns_without_climatezones = columns_without_climatezones.drop([col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to make regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_regression(regression,dataframe):\n",
    "    ##Must make dummies for categorical variable climate_zone\n",
    "    # dataframe = pd.get_dummies(dataframe, columns=['climate_zone'])\n",
    "    # Or just drop column if don't want dummies: x = x.drop(['climate_zone'], axis=1)\n",
    "\n",
    "    x = dataframe.drop(['calories_per_ha'], axis=1)\n",
    "    y = dataframe['calories_per_ha']\n",
    "\n",
    "    ### Cross validation scores\n",
    "    r2_scores = cross_val_score(regression, x, y, cv=5,scoring='r2')\n",
    "    mse_scores = cross_val_score(regression, x, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    mae_scores = 0 #cross_val_score(regression, x, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "    \n",
    "    return [np.mean(r2_scores),np.mean(mse_scores),np.mean(mae_scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_predictions(regression,dataframe,show_df=True,show_plot=True):\n",
    "    x = dataframe.drop(['calories_per_ha','climate_zones'], axis=1)\n",
    "    y = dataframe['calories_per_ha']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "    reg = regression.fit(X_train, y_train)\n",
    "    y_predicted = reg.predict(X_test)\n",
    "\n",
    "    compare = pd.DataFrame()\n",
    "    compare['y_test'] = y_test\n",
    "    compare['predicted'] = y_predicted\n",
    "\n",
    "    if show_plot == True:\n",
    "        ax = compare.plot.scatter(x='y_test',y='predicted',s=0.5)\n",
    "        ax.plot(ax.get_xlim(), ax.get_xlim(), ls=\"--\", c=\".3\")\n",
    "        \n",
    "    return compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run_regressions_and_save_results(model, regression, dataframe, features_selection,\n",
    "                                     results_df,parameters_dict=None,inputs = None):\n",
    "    '''features_selection = 'all', 'all_but_climzones', 'RFE', 'RFE_but_climzones   '''\n",
    "\n",
    "    # - - - - - - - - - - - - - - \n",
    "    # Features = All\n",
    "    # - - - - - - - - - - - - - - \n",
    "    \n",
    "    if features_selection == 'all':\n",
    "        print('    with all features...')\n",
    "        Features = 'All w/ climzones'\n",
    "        \n",
    "        scores = do_regression(regression,dataframe)\n",
    "        \n",
    "        print('    R2_score : '+str(scores[0]))\n",
    "        print('    MSE_score : '+str(scores[1]))\n",
    "        R2_score = scores[0]\n",
    "        MSE_score = scores[1]\n",
    "        results_df = results_df.append({'Model': model,\n",
    "                                        'num_features':len(dataframe.columns)-1,'Features':Features,\n",
    "                                        'params':parameters_dict,\n",
    "                                        'R2':R2_score,'MSE':MSE_score},ignore_index=True)\n",
    "        \n",
    "        \n",
    "    # - - - - - - - - - - - - - - -\n",
    "    # Features = All but climzones\n",
    "    # - - - - - - - - - - - - - - -\n",
    "    \n",
    "    elif features_selection == 'all_but_climzones':\n",
    "        dataframe = dataframe[columns_without_climatezones]\n",
    "        \n",
    "        print('    with all features but climate zones...')\n",
    "        Features = 'All w/o climzones'\n",
    "        \n",
    "        scores = do_regression(regression,dataframe)\n",
    "        \n",
    "        print('    R2_score : '+str(scores[0]))\n",
    "        print('    MSE_score : '+str(scores[1]))\n",
    "        R2_score = scores[0]\n",
    "        MSE_score = scores[1]\n",
    "        results_df = results_df.append({'Model': model,\n",
    "                                        'num_features':len(dataframe.columns)-1,'Features':Features,\n",
    "                                        'params':parameters_dict,\n",
    "                                    'R2':R2_score,'MSE':MSE_score},ignore_index=True)\n",
    "           \n",
    "    \n",
    "    # - - - - - - - - - - - - - - -\n",
    "    # Features = SUBSET\n",
    "    # - - - - - - - - - - - - - - -\n",
    "    \n",
    "    # if features_selection = 'subset':\n",
    "    ## TODO\n",
    "    \n",
    "    \n",
    "    # - - - - - - - - - - - - - - - - - - - - - - -\n",
    "    # Features = RFE selected (with climate zones)\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - -\n",
    "    \n",
    "    elif features_selection == 'RFE':\n",
    "        for num_features in range (5,30):\n",
    "\n",
    "            print(' RFE with '+str(num_features)+ ' features ...')\n",
    "\n",
    "            ## RFE - Features selection\n",
    "            selector = RFE(regression, num_features, step=1)\n",
    "            x = dataframe.drop(['calories_per_ha'], axis=1) \n",
    "            y = dataframe['calories_per_ha']\n",
    "            X, X_test, Y, Y_test = train_test_split(x, y)\n",
    "            X_RFE = selector.fit_transform(X,Y)\n",
    "            features_selected = [X.columns[feature_pos] for feature_pos in selector.get_support(indices=True)]\n",
    "            \n",
    "            # Do regression and append results to results_df\n",
    "            scores = do_regression(regression,dataframe[(features_selected + ['calories_per_ha'])])\n",
    "            print('    R2_score : '+str(scores[0]))\n",
    "            print('    MSE_score : '+str(scores[1]))\n",
    "            R2_score = scores[0]\n",
    "            MSE_score = scores[1]\n",
    "            results_df = results_df.append({'Model': model,\n",
    "                                    'num_features':num_features,'Features':features_selected,\n",
    "                                     'params':parameters_dict,\n",
    "                                    'R2':R2_score,'MSE':MSE_score},ignore_index=True)\n",
    "        \n",
    "        \n",
    "    # - - - - - - - - - - - - - - - - - - - - - - \n",
    "    # Features = RFE selected (w/o climate zones)\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - \n",
    "    \n",
    "    elif features_selection == 'RFE_but_climzones':\n",
    "        \n",
    "        dataframe = dataframe[columns_without_climatezones]\n",
    "        \n",
    "        for num_features in range (5,30):\n",
    "\n",
    "            print('RFE (no climzones) with '+str(num_features)+ ' features ...')\n",
    "\n",
    "            ## RFE - Features selection\n",
    "            selector = RFE(regression, num_features, step=1)\n",
    "            x = dataframe.drop(['calories_per_ha'], axis=1) \n",
    "            y = dataframe['calories_per_ha']\n",
    "            X, X_test, Y, Y_test = train_test_split(x, y)\n",
    "            X_RFE = selector.fit_transform(X,Y)\n",
    "            features_selected = [X.columns[feature_pos] for feature_pos in selector.get_support(indices=True)]\n",
    "   \n",
    "            # Do regression and append results to results_df\n",
    "            scores = do_regression(regression,dataframe[(features_selected + ['calories_per_ha'])])\n",
    "            print('    R2_score : '+str(scores[0]))\n",
    "            print('    MSE_score : '+str(scores[1]))\n",
    "            R2_score = scores[0]\n",
    "            MSE_score = scores[1]\n",
    "            results_df = results_df.append({'Model': model,\n",
    "                                    'num_features':num_features,'Features':features_selected,\n",
    "                                    'params':parameters_dict,\n",
    "                                    'R2':R2_score,'MSE':MSE_score},ignore_index=True)\n",
    "            \n",
    "    elif features_selection == 'RFE_8_20':\n",
    "        \n",
    "        \n",
    "        for num_features in [8,20]:\n",
    "\n",
    "            print('RFE with '+str(num_features)+ ' features ...')\n",
    "\n",
    "            ## RFE - Features selection\n",
    "            selector = RFE(regression, num_features, step=1)\n",
    "            x = dataframe.drop(['calories_per_ha'], axis=1) \n",
    "            y = dataframe['calories_per_ha']\n",
    "            X, X_test, Y, Y_test = train_test_split(x, y)\n",
    "            X_RFE = selector.fit_transform(X,Y)\n",
    "            features_selected = [X.columns[feature_pos] for feature_pos in selector.get_support(indices=True)]\n",
    "   \n",
    "            # Do regression and append results to results_df\n",
    "            scores = do_regression(regression,dataframe[(features_selected + ['calories_per_ha'])])\n",
    "            print('    R2_score : '+str(scores[0]))\n",
    "            print('    MSE_score : '+str(scores[1]))\n",
    "            R2_score = scores[0]\n",
    "            MSE_score = scores[1]\n",
    "            results_df = results_df.append({'Model': model,\n",
    "                                    'num_features':num_features,'Features':features_selected,\n",
    "                                    'params':parameters_dict,\n",
    "                                    'R2':R2_score,'MSE':MSE_score,\n",
    "                                    'inputs' : inputs},ignore_index=True)\n",
    "    \n",
    "        \n",
    "    return(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Validation R2 and save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk (once fitted)\n",
    "def save_model(filename):\n",
    "    pickle.dump(regression, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test\n",
    "\n",
    "\n",
    "validation_R2 = pd.DataFrame(columns=['Model','Validation_R2'])\n",
    "\n",
    "#Â #Â #Â - - - LinearÂ - - - #Â #Â #\n",
    "\n",
    "model = 'Linear'\n",
    "regression = LinearRegression()\n",
    "\n",
    "X_train = df.drop(['calories_per_ha'], axis=1)\n",
    "y_train = df['calories_per_ha']\n",
    "regression.fit(X_train, y_train)\n",
    "save_model('../ipbes_invest_crop_yield_project/output/Models/'+model+'.sav')\n",
    "y_predicted = regression.predict(X_validation)\n",
    "\n",
    "R2_validation = sklearn.metrics.r2_score(y_validation, y_predicted)\n",
    "validation_R2 = validation_R2.append({'Model':model,'Validation_R2':R2_validation},ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â #Â #Â - - - XGBÂ - - - #Â #Â #\n",
    "model = 'xgb3'\n",
    "best_parameters3 = {'colsample_bytree': 0.85, 'learning_rate': 0.02, 'max_depth': 10,\n",
    " 'min_child_weight': 3, 'n_estimators': 700, 'nthread': 4,\n",
    " 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.85}\n",
    "regression = xgb.XGBRegressor(**best_parameters3)\n",
    "\n",
    "X_train = df.drop(['calories_per_ha'], axis=1)\n",
    "y_train = df['calories_per_ha']\n",
    "regression.fit(X_train, y_train)\n",
    "save_model('../ipbes_invest_crop_yield_project/output/Models/'+model+'.sav')\n",
    "y_predicted = regression.predict(X_validation)\n",
    "\n",
    "R2_validation = sklearn.metrics.r2_score(y_validation, y_predicted)\n",
    "validation_R2 = validation_R2.append({'Model':model,'Validation_R2':R2_validation},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â #Â #Â - - - LassoÂ - - - #Â #Â #\n",
    "\n",
    "model = 'Lasso'\n",
    "best_params_Lasso = {'alpha': 0.001, 'max_iter': 1000, 'selection': 'random', 'tol': 0.0001}\n",
    "regression = Lasso(**best_params_Lasso)\n",
    "\n",
    "X_train = df.drop(['calories_per_ha'], axis=1)\n",
    "y_train = df['calories_per_ha']\n",
    "regression.fit(X_train, y_train)\n",
    "save_model('../ipbes_invest_crop_yield_project/output/Models/'+model+'.sav')\n",
    "y_predicted = regression.predict(X_validation)\n",
    "\n",
    "R2_validation = sklearn.metrics.r2_score(y_validation, y_predicted)\n",
    "validation_R2 = validation_R2.append({'Model':model,'Validation_R2':R2_validation},ignore_index=True)\n",
    "\n",
    "#Â #Â #Â - - - RidgeÂ - - - #Â #Â #\n",
    "\n",
    "model = 'Ridge'\n",
    "best_paramsR = {'alpha': 0.001, 'max_iter': 1000, 'tol': 1e-06}\n",
    "regression = Ridge(**best_paramsR)\n",
    "\n",
    "X_train = df.drop(['calories_per_ha'], axis=1)\n",
    "y_train = df['calories_per_ha']\n",
    "regression.fit(X_train, y_train)\n",
    "save_model('../ipbes_invest_crop_yield_project/output/Models/'+model+'.sav')\n",
    "y_predicted = regression.predict(X_validation)\n",
    "\n",
    "R2_validation = sklearn.metrics.r2_score(y_validation, y_predicted)\n",
    "validation_R2 = validation_R2.append({'Model':model,'Validation_R2':R2_validation},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Validation_R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear</td>\n",
       "      <td>0.310224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgb3</td>\n",
       "      <td>0.702847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.309753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.310224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  Validation_R2\n",
       "0  Linear       0.310224\n",
       "1    xgb3       0.702847\n",
       "2   Lasso       0.309753\n",
       "3   Ridge       0.310224"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_R2.to_csv('../ipbes_invest_crop_yield_project/output/R2_Validation/R2_validation_allinputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO -- a little tricker to get Polynomial (make_X_polynomial to fix because no 'pixel_id')\n",
    "* For now, skip because Lasso gives better results anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_polynomial(df, degree = 2, interaction_terms = True):\n",
    "#'''Returns a new dataFrame with added polynomial terms degree >= 2'''\n",
    "\n",
    "\n",
    "    if interaction_terms == False:\n",
    "        x = df.drop(['calories_per_ha'], axis=1)\n",
    "        y = df['calories_per_ha']\n",
    "\n",
    "        for deg in range(2,degree+1):\n",
    "            for col in x.columns:\n",
    "                x[str(col+'^'+str(deg))] = x[col].apply(lambda x:x**deg)\n",
    "        \n",
    "        Poly_df = x.merge(pd.DataFrame(y),right_index=True,left_index=True)\n",
    "\n",
    "    if interaction_terms == True:\n",
    "        x = df.drop(['calories_per_ha'], axis=1)\n",
    "        y = df['calories_per_ha'].reset_index()\n",
    "\n",
    "        poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "        X2 = poly.fit_transform(x)\n",
    "\n",
    "        Poly_df = pd.DataFrame(data = np.concatenate((y.as_matrix(),X2),axis=1),\n",
    "                               columns = ['pixel_id','calories_per_ha'] +\n",
    "                               poly.get_feature_names((df.drop(['calories_per_ha'], axis=1)).columns))\n",
    "\n",
    "        Poly_df = Poly_df.set_index('pixel_id')\n",
    "\n",
    "    return Poly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_R2 = pd.DataFrame(columns=['Model','Validation_R2'])\n",
    "\n",
    "#Â #Â #Â - - - PolyÂ - - - #Â #Â #\n",
    "#(Barbarian way)\n",
    "\n",
    "model = 'Poly'\n",
    "regression = LinearRegression()\n",
    "\n",
    "df2 = make_polynomial(df)\n",
    "\n",
    "df_validation = X_validation.merge(pd.DataFrame(y_validation),right_index=True,left_index=True)\n",
    "df_val_poly = make_polynomial(df_validation)\n",
    "X_val2 = df_val_poly.drop(['calories_per_ha'], axis=1)\n",
    "\n",
    "X_train = df2.drop(['calories_per_ha'], axis=1)\n",
    "y_train = df2['calories_per_ha']\n",
    "regression.fit(X_train, y_train)\n",
    "save_model('../ipbes_invest_crop_yield_project/output/Models/'+model+'.sav')\n",
    "y_predicted = regression.predict(X_val2)\n",
    "\n",
    "R2_validation = sklearn.metrics.r2_score(y_validation, y_predicted)\n",
    "validation_R2 = validation_R2.append({'Model':model,'Validation_R2':R2_validation},ignore_index=True)\n",
    "\n",
    "validation_R2.to_csv('../ipbes_invest_crop_yield_project/output/R2_Validation/R2_validation_allinputs_POLY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Validation_R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Poly</td>\n",
       "      <td>0.450667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Validation_R2\n",
       "0  Poly       0.450667"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Validation_R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Poly</td>\n",
       "      <td>0.450667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear</td>\n",
       "      <td>0.306051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  Validation_R2\n",
       "0    Poly       0.450667\n",
       "1  Linear       0.306051"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = 'Linear'\n",
    "regression = LinearRegression()\n",
    "\n",
    "X_train = df.drop(['calories_per_ha'], axis=1)\n",
    "y_train = df['calories_per_ha']\n",
    "regression.fit(X_train, y_train)\n",
    "save_model('../ipbes_invest_crop_yield_project/output/Models/'+model+'.sav')\n",
    "y_predicted = regression.predict(X_validation)\n",
    "\n",
    "R2_validation = sklearn.metrics.r2_score(y_validation, y_predicted)\n",
    "validation_R2 = validation_R2.append({'Model':model,'Validation_R2':R2_validation},ignore_index=True)\n",
    "\n",
    "validation_R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = pd.read_csv('../ipbes_invest_crop_yield_project/output/R2_Validation/R2_validation_allinputs.csv')\n",
    "v2 = pd.read_csv('../ipbes_invest_crop_yield_project/output/R2_Validation/R2_validation_allinputs_POLY')\n",
    "\n",
    "v3 = pd.concat([v1,v2],ignore_index=True)\n",
    "\n",
    "#v3.to_csv('../ipbes_invest_crop_yield_project/output/R2_Validation/R2_validation_allinputs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "v4 = v3.drop(index=5)\n",
    "\n",
    "v4.to_csv('../ipbes_invest_crop_yield_project/output/R2_Validation/R2_validation_allinputs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3.to_csv('../ipbes_invest_crop_yield_project/output/R2_Validation/R2_validation_allinputs_POLY')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spatialenv]",
   "language": "python",
   "name": "conda-env-spatialenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
